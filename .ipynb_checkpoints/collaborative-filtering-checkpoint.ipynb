{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "## ***Company-based Capstone Project***\n",
    "#### **Team ID\t\t: C24-MR01**\n",
    "\n",
    "Team Member\t: \n",
    "\n",
    "(ML) M002D4KY2877 - Auvarifqi Putra Diandra\n",
    "\n",
    "(ML) M010D4KY3370 - Rafi Madani\n",
    "\n",
    "(ML) M002D4KY2625 - Iskandar Muda Rizky Parlambang\n",
    "\n",
    "(MD) A010D4KY4202 - Muhammad Adryan Haska Putra\n",
    "\n",
    "(MD) A297D4KX4551 - Vena Feranica\n",
    "\n",
    "(CC) C002D4KY1032 - Muhammad Naufal\n",
    "\n",
    "(CC) C459D4KY0090 - Jamaludin Ahmad Rifai\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>raw_user_age</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>7</td>\n",
       "      <td>510</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>46.0</td>\n",
       "      <td>879024327</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>doctor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5</td>\n",
       "      <td>680</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>50.0</td>\n",
       "      <td>883326919</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>4.0</td>\n",
       "      <td>06472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4233</td>\n",
       "      <td>Scream 2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>891409199</td>\n",
       "      <td>True</td>\n",
       "      <td>197</td>\n",
       "      <td>18</td>\n",
       "      <td>technician</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1640</td>\n",
       "      <td>Crash</td>\n",
       "      <td>19.0</td>\n",
       "      <td>876346551</td>\n",
       "      <td>False</td>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "      <td>artist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>812</td>\n",
       "      <td>Aladdin</td>\n",
       "      <td>19.0</td>\n",
       "      <td>882064434</td>\n",
       "      <td>True</td>\n",
       "      <td>710</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>True Romance</td>\n",
       "      <td>34.0</td>\n",
       "      <td>875135363</td>\n",
       "      <td>True</td>\n",
       "      <td>833</td>\n",
       "      <td>21</td>\n",
       "      <td>writer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>563</td>\n",
       "      <td>Starship Troopers</td>\n",
       "      <td>32.0</td>\n",
       "      <td>884801053</td>\n",
       "      <td>True</td>\n",
       "      <td>940</td>\n",
       "      <td>2</td>\n",
       "      <td>administrator</td>\n",
       "      <td>2.0</td>\n",
       "      <td>02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10153</td>\n",
       "      <td>Sphere</td>\n",
       "      <td>46.0</td>\n",
       "      <td>891636399</td>\n",
       "      <td>True</td>\n",
       "      <td>611</td>\n",
       "      <td>10</td>\n",
       "      <td>librarian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.0</td>\n",
       "      <td>7</td>\n",
       "      <td>26748</td>\n",
       "      <td>Lone Star</td>\n",
       "      <td>21.0</td>\n",
       "      <td>880913800</td>\n",
       "      <td>True</td>\n",
       "      <td>276</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1624</td>\n",
       "      <td>Liar Liar</td>\n",
       "      <td>34.0</td>\n",
       "      <td>887667681</td>\n",
       "      <td>True</td>\n",
       "      <td>510</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucketized_user_age  movie_genres  movie_id  \\\n",
       "0                 45.0             7       510   \n",
       "1                 50.0             5       680   \n",
       "2                 50.0            10      4233   \n",
       "3                 18.0             7      1640   \n",
       "4                 18.0             2       812   \n",
       "5                 25.0             0       319   \n",
       "6                 25.0             0       563   \n",
       "7                 45.0             1     10153   \n",
       "8                 18.0             7     26748   \n",
       "9                 25.0             4      1624   \n",
       "\n",
       "                       movie_title  raw_user_age  timestamp  user_gender  \\\n",
       "0  One Flew Over the Cuckoo's Nest          46.0  879024327         True   \n",
       "1                     Pulp Fiction          50.0  883326919         True   \n",
       "2                         Scream 2          55.0  891409199         True   \n",
       "3                            Crash          19.0  876346551        False   \n",
       "4                          Aladdin          19.0  882064434         True   \n",
       "5                     True Romance          34.0  875135363         True   \n",
       "6                Starship Troopers          32.0  884801053         True   \n",
       "7                           Sphere          46.0  891636399         True   \n",
       "8                        Lone Star          21.0  880913800         True   \n",
       "9                        Liar Liar          34.0  887667681         True   \n",
       "\n",
       "   user_id  user_occupation_label user_occupation_text  user_rating  \\\n",
       "0      138                      4               doctor          4.0   \n",
       "1       60                      4           healthcare          4.0   \n",
       "2      197                     18           technician          3.0   \n",
       "3      601                      1               artist          4.0   \n",
       "4      710                     17              student          3.0   \n",
       "5      833                     21               writer          2.0   \n",
       "6      940                      2        administrator          2.0   \n",
       "7      611                     10            librarian          1.0   \n",
       "8      276                     17              student          5.0   \n",
       "9      510                     11                other          3.0   \n",
       "\n",
       "  user_zip_code  \n",
       "0         53211  \n",
       "1         06472  \n",
       "2         75094  \n",
       "3         99687  \n",
       "4         92020  \n",
       "5         90019  \n",
       "6         02215  \n",
       "7         77008  \n",
       "8         95064  \n",
       "9         98038  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './data'\n",
    "ratings_df = pd.read_csv(f\"{data_path}/ratings_fix.csv\")\n",
    "ratings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45495 entries, 0 to 45494\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   bucketized_user_age    45495 non-null  float64\n",
      " 1   movie_genres           45495 non-null  int64  \n",
      " 2   movie_id               45495 non-null  int64  \n",
      " 3   movie_title            45495 non-null  object \n",
      " 4   raw_user_age           45495 non-null  float64\n",
      " 5   timestamp              45495 non-null  int64  \n",
      " 6   user_gender            45495 non-null  bool   \n",
      " 7   user_id                45495 non-null  int64  \n",
      " 8   user_occupation_label  45495 non-null  int64  \n",
      " 9   user_occupation_text   45495 non-null  object \n",
      " 10  user_rating            45495 non-null  float64\n",
      " 11  user_zip_code          45495 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(5), object(3)\n",
      "memory usage: 3.9+ MB\n",
      "\n",
      "Jumlah data: 45495\n",
      "Jumlah atribut: 12\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 45482 entries, 0 to 45494\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   bucketized_user_age    45482 non-null  float64\n",
      " 1   movie_genres           45482 non-null  int64  \n",
      " 2   movie_id               45482 non-null  int64  \n",
      " 3   movie_title            45482 non-null  object \n",
      " 4   raw_user_age           45482 non-null  float64\n",
      " 5   timestamp              45482 non-null  int64  \n",
      " 6   user_gender            45482 non-null  bool   \n",
      " 7   user_id                45482 non-null  int64  \n",
      " 8   user_occupation_label  45482 non-null  int64  \n",
      " 9   user_occupation_text   45482 non-null  object \n",
      " 10  user_rating            45482 non-null  float64\n",
      " 11  user_zip_code          45482 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(5), object(3)\n",
      "memory usage: 4.2+ MB\n",
      "\n",
      "Jumlah data: 45482\n",
      "Jumlah atribut: 12\n"
     ]
    }
   ],
   "source": [
    "ratings_df.info()\n",
    "total_rows, total_attributes = ratings_df.shape\n",
    "print()\n",
    "print('Jumlah data:', total_rows)\n",
    "print(\"Jumlah atribut:\", total_attributes)\n",
    "\n",
    "ratings_df = ratings_df.drop_duplicates()\n",
    "\n",
    "ratings_df.info()\n",
    "total_rows, total_attributes = ratings_df.shape\n",
    "print()\n",
    "print('Jumlah data:', total_rows)\n",
    "print(\"Jumlah atribut:\", total_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.shape\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Definisikan fungsi assign_like\n",
    "def assign_like(user_rating):\n",
    "    if user_rating > 3.5:\n",
    "        return 1 # Nilai acak 0 atau 1 untuk rating > 3.5\n",
    "    else:\n",
    "        return 0  # Nilai 0 untuk rating <= 3.5\n",
    "\n",
    "# Terapkan fungsi ke kolom 'user_rating' untuk membuat kolom 'like'\n",
    "ratings_df['like'] = ratings_df['user_rating'].apply(assign_like)\n",
    "# ratings_df['like'] = np.random.randint(0, 2, size=len(ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>raw_user_age</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>7</td>\n",
       "      <td>510</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>46.0</td>\n",
       "      <td>879024327</td>\n",
       "      <td>True</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>doctor</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5</td>\n",
       "      <td>680</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>50.0</td>\n",
       "      <td>883326919</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>4.0</td>\n",
       "      <td>06472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4233</td>\n",
       "      <td>Scream 2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>891409199</td>\n",
       "      <td>True</td>\n",
       "      <td>197</td>\n",
       "      <td>18</td>\n",
       "      <td>technician</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1640</td>\n",
       "      <td>Crash</td>\n",
       "      <td>19.0</td>\n",
       "      <td>876346551</td>\n",
       "      <td>False</td>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "      <td>artist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>812</td>\n",
       "      <td>Aladdin</td>\n",
       "      <td>19.0</td>\n",
       "      <td>882064434</td>\n",
       "      <td>True</td>\n",
       "      <td>710</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucketized_user_age  movie_genres  movie_id  \\\n",
       "0                 45.0             7       510   \n",
       "1                 50.0             5       680   \n",
       "2                 50.0            10      4233   \n",
       "3                 18.0             7      1640   \n",
       "4                 18.0             2       812   \n",
       "\n",
       "                       movie_title  raw_user_age  timestamp  user_gender  \\\n",
       "0  One Flew Over the Cuckoo's Nest          46.0  879024327         True   \n",
       "1                     Pulp Fiction          50.0  883326919         True   \n",
       "2                         Scream 2          55.0  891409199         True   \n",
       "3                            Crash          19.0  876346551        False   \n",
       "4                          Aladdin          19.0  882064434         True   \n",
       "\n",
       "   user_id  user_occupation_label user_occupation_text  user_rating  \\\n",
       "0      138                      4               doctor          4.0   \n",
       "1       60                      4           healthcare          4.0   \n",
       "2      197                     18           technician          3.0   \n",
       "3      601                      1               artist          4.0   \n",
       "4      710                     17              student          3.0   \n",
       "\n",
       "  user_zip_code  like  \n",
       "0         53211     1  \n",
       "1         06472     1  \n",
       "2         75094     0  \n",
       "3         99687     1  \n",
       "4         92020     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943, Number of Movies: 378, Min rating: 1.0, Max rating: 5.0\n",
      "{138: 0, 60: 1, 197: 2, 601: 3, 710: 4, 833: 5, 940: 6, 611: 7, 276: 8, 510: 9, 246: 10, 91: 11, 372: 12, 615: 13, 195: 14, 676: 15, 634: 16, 505: 17, 293: 18, 350: 19, 404: 20, 28: 21, 428: 22, 733: 23, 354: 24, 486: 25, 669: 26, 535: 27, 560: 28, 407: 29, 109: 30, 643: 31, 585: 32, 222: 33, 330: 34, 26: 35, 113: 36, 684: 37, 783: 38, 194: 39, 76: 40, 943: 41, 663: 42, 139: 43, 435: 44, 417: 45, 290: 46, 303: 47, 144: 48, 653: 49, 844: 50, 708: 51, 255: 52, 336: 53, 10: 54, 561: 55, 886: 56, 204: 57, 899: 58, 871: 59, 677: 60, 41: 61, 158: 62, 271: 63, 320: 64, 343: 65, 761: 66, 263: 67, 618: 68, 25: 69, 499: 70, 589: 71, 805: 72, 920: 73, 247: 74, 291: 75, 625: 76, 771: 77, 666: 78, 699: 79, 693: 80, 787: 81, 661: 82, 502: 83, 30: 84, 390: 85, 94: 86, 715: 87, 711: 88, 386: 89, 496: 90, 198: 91, 472: 92, 856: 93, 214: 94, 347: 95, 697: 96, 622: 97, 638: 98, 130: 99, 254: 100, 394: 101, 206: 102, 396: 103, 543: 104, 256: 105, 889: 106, 881: 107, 13: 108, 913: 109, 305: 110, 243: 111, 73: 112, 667: 113, 645: 114, 325: 115, 682: 116, 641: 117, 378: 118, 679: 119, 562: 120, 3: 121, 504: 122, 501: 123, 268: 124, 406: 125, 387: 126, 110: 127, 1: 128, 766: 129, 389: 130, 466: 131, 286: 132, 119: 133, 450: 134, 468: 135, 216: 136, 917: 137, 600: 138, 546: 139, 463: 140, 770: 141, 402: 142, 345: 143, 670: 144, 332: 145, 253: 146, 223: 147, 738: 148, 346: 149, 807: 150, 488: 151, 548: 152, 315: 153, 689: 154, 746: 155, 493: 156, 16: 157, 416: 158, 868: 159, 749: 160, 655: 161, 536: 162, 863: 163, 862: 164, 334: 165, 796: 166, 327: 167, 49: 168, 792: 169, 68: 170, 683: 171, 495: 172, 860: 173, 904: 174, 65: 175, 374: 176, 506: 177, 328: 178, 437: 179, 181: 180, 448: 181, 135: 182, 319: 183, 675: 184, 39: 185, 92: 186, 703: 187, 896: 188, 613: 189, 442: 190, 764: 191, 324: 192, 790: 193, 642: 194, 201: 195, 524: 196, 795: 197, 233: 198, 741: 199, 79: 200, 938: 201, 887: 202, 909: 203, 356: 204, 786: 205, 629: 206, 921: 207, 758: 208, 318: 209, 217: 210, 339: 211, 89: 212, 117: 213, 7: 214, 705: 215, 727: 216, 401: 217, 363: 218, 279: 219, 874: 220, 840: 221, 310: 222, 453: 223, 215: 224, 687: 225, 42: 226, 456: 227, 476: 228, 178: 229, 883: 230, 878: 231, 145: 232, 918: 233, 650: 234, 507: 235, 595: 236, 452: 237, 567: 238, 725: 239, 296: 240, 258: 241, 534: 242, 62: 243, 165: 244, 823: 245, 513: 246, 405: 247, 210: 248, 537: 249, 551: 250, 5: 251, 532: 252, 329: 253, 193: 254, 162: 255, 498: 256, 577: 257, 875: 258, 95: 259, 620: 260, 59: 261, 894: 262, 916: 263, 826: 264, 423: 265, 15: 266, 897: 267, 936: 268, 919: 269, 523: 270, 454: 271, 609: 272, 207: 273, 608: 274, 53: 275, 43: 276, 224: 277, 72: 278, 605: 279, 624: 280, 851: 281, 395: 282, 457: 283, 297: 284, 838: 285, 864: 286, 420: 287, 69: 288, 18: 289, 451: 290, 716: 291, 584: 292, 804: 293, 44: 294, 27: 295, 52: 296, 323: 297, 133: 298, 275: 299, 785: 300, 101: 301, 399: 302, 425: 303, 870: 304, 626: 305, 865: 306, 802: 307, 83: 308, 298: 309, 429: 310, 511: 311, 837: 312, 427: 313, 29: 314, 503: 315, 299: 316, 902: 317, 163: 318, 533: 319, 753: 320, 846: 321, 815: 322, 455: 323, 384: 324, 885: 325, 307: 326, 381: 327, 489: 328, 371: 329, 789: 330, 151: 331, 491: 332, 21: 333, 774: 334, 411: 335, 249: 336, 831: 337, 763: 338, 104: 339, 57: 340, 422: 341, 77: 342, 788: 343, 723: 344, 116: 345, 712: 346, 828: 347, 23: 348, 518: 349, 479: 350, 269: 351, 367: 352, 392: 353, 531: 354, 474: 355, 285: 356, 87: 357, 364: 358, 82: 359, 189: 360, 141: 361, 890: 362, 782: 363, 740: 364, 671: 365, 780: 366, 14: 367, 579: 368, 478: 369, 283: 370, 379: 371, 724: 372, 166: 373, 311: 374, 550: 375, 747: 376, 63: 377, 306: 378, 648: 379, 659: 380, 582: 381, 326: 382, 922: 383, 149: 384, 911: 385, 756: 386, 397: 387, 526: 388, 933: 389, 737: 390, 148: 391, 778: 392, 564: 393, 168: 394, 152: 395, 115: 396, 61: 397, 308: 398, 751: 399, 262: 400, 768: 401, 274: 402, 485: 403, 259: 404, 797: 405, 102: 406, 11: 407, 734: 408, 360: 409, 892: 410, 99: 411, 709: 412, 96: 413, 150: 414, 907: 415, 348: 416, 200: 417, 484: 418, 190: 419, 812: 420, 549: 421, 157: 422, 244: 423, 623: 424, 719: 425, 800: 426, 731: 427, 587: 428, 694: 429, 170: 430, 137: 431, 90: 432, 106: 433, 280: 434, 627: 435, 606: 436, 934: 437, 932: 438, 923: 439, 136: 440, 915: 441, 497: 442, 614: 443, 557: 444, 50: 445, 798: 446, 931: 447, 750: 448, 680: 449, 97: 450, 35: 451, 391: 452, 529: 453, 370: 454, 313: 455, 570: 456, 592: 457, 593: 458, 358: 459, 542: 460, 721: 461, 843: 462, 654: 463, 658: 464, 555: 465, 234: 466, 743: 467, 590: 468, 45: 469, 211: 470, 832: 471, 559: 472, 376: 473, 24: 474, 748: 475, 538: 476, 942: 477, 235: 478, 660: 479, 70: 480, 167: 481, 500: 482, 901: 483, 545: 484, 218: 485, 806: 486, 714: 487, 175: 488, 257: 489, 164: 490, 238: 491, 640: 492, 718: 493, 252: 494, 38: 495, 112: 496, 146: 497, 827: 498, 481: 499, 849: 500, 544: 501, 632: 502, 880: 503, 342: 504, 657: 505, 184: 506, 912: 507, 186: 508, 527: 509, 67: 510, 521: 511, 646: 512, 619: 513, 129: 514, 393: 515, 834: 516, 20: 517, 173: 518, 352: 519, 460: 520, 383: 521, 85: 522, 490: 523, 757: 524, 830: 525, 239: 526, 312: 527, 664: 528, 400: 529, 160: 530, 267: 531, 867: 532, 316: 533, 227: 534, 301: 535, 121: 536, 88: 537, 927: 538, 597: 539, 848: 540, 773: 541, 910: 542, 289: 543, 644: 544, 845: 545, 250: 546, 566: 547, 730: 548, 905: 549, 825: 550, 426: 551, 900: 552, 128: 553, 418: 554, 617: 555, 841: 556, 147: 557, 169: 558, 937: 559, 514: 560, 100: 561, 612: 562, 706: 563, 187: 564, 445: 565, 929: 566, 754: 567, 287: 568, 433: 569, 251: 570, 408: 571, 54: 572, 292: 573, 492: 574, 199: 575, 432: 576, 803: 577, 720: 578, 872: 579, 179: 580, 588: 581, 281: 582, 784: 583, 337: 584, 662: 585, 294: 586, 322: 587, 236: 588, 403: 589, 188: 590, 794: 591, 33: 592, 355: 593, 440: 594, 191: 595, 586: 596, 596: 597, 75: 598, 854: 599, 755: 600, 409: 601, 458: 602, 637: 603, 690: 604, 46: 605, 487: 606, 385: 607, 810: 608, 903: 609, 446: 610, 630: 611, 668: 612, 616: 613, 221: 614, 174: 615, 574: 616, 122: 617, 695: 618, 554: 619, 159: 620, 12: 621, 508: 622, 203: 623, 553: 624, 839: 625, 475: 626, 665: 627, 377: 628, 610: 629, 248: 630, 924: 631, 126: 632, 853: 633, 161: 634, 66: 635, 80: 636, 434: 637, 314: 638, 264: 639, 633: 640, 745: 641, 760: 642, 776: 643, 351: 644, 635: 645, 410: 646, 639: 647, 171: 648, 270: 649, 941: 650, 580: 651, 56: 652, 530: 653, 829: 654, 74: 655, 22: 656, 32: 657, 541: 658, 176: 659, 647: 660, 850: 661, 373: 662, 752: 663, 722: 664, 465: 665, 380: 666, 884: 667, 818: 668, 333: 669, 436: 670, 447: 671, 700: 672, 568: 673, 558: 674, 895: 675, 19: 676, 398: 677, 213: 678, 368: 679, 288: 680, 321: 681, 177: 682, 717: 683, 879: 684, 9: 685, 58: 686, 125: 687, 576: 688, 728: 689, 603: 690, 240: 691, 906: 692, 344: 693, 928: 694, 621: 695, 882: 696, 571: 697, 237: 698, 4: 699, 341: 700, 604: 701, 939: 702, 131: 703, 842: 704, 232: 705, 230: 706, 707: 707, 8: 708, 114: 709, 357: 710, 701: 711, 361: 712, 515: 713, 143: 714, 781: 715, 6: 716, 519: 717, 272: 718, 182: 719, 735: 720, 520: 721, 205: 722, 412: 723, 172: 724, 64: 725, 439: 726, 359: 727, 692: 728, 245: 729, 877: 730, 464: 731, 462: 732, 914: 733, 81: 734, 759: 735, 459: 736, 859: 737, 103: 738, 127: 739, 847: 740, 295: 741, 105: 742, 2: 743, 552: 744, 698: 745, 123: 746, 674: 747, 935: 748, 772: 749, 673: 750, 591: 751, 419: 752, 836: 753, 449: 754, 108: 755, 767: 756, 547: 757, 84: 758, 192: 759, 40: 760, 852: 761, 563: 762, 17: 763, 821: 764, 156: 765, 37: 766, 688: 767, 142: 768, 775: 769, 208: 770, 651: 771, 540: 772, 366: 773, 822: 774, 185: 775, 124: 776, 809: 777, 876: 778, 362: 779, 107: 780, 55: 781, 869: 782, 483: 783, 36: 784, 649: 785, 811: 786, 573: 787, 431: 788, 284: 789, 908: 790, 71: 791, 473: 792, 631: 793, 180: 794, 277: 795, 480: 796, 525: 797, 365: 798, 266: 799, 779: 800, 835: 801, 819: 802, 569: 803, 212: 804, 229: 805, 578: 806, 512: 807, 300: 808, 817: 809, 118: 810, 791: 811, 154: 812, 265: 813, 231: 814, 509: 815, 528: 816, 438: 817, 678: 818, 338: 819, 742: 820, 583: 821, 702: 822, 120: 823, 925: 824, 369: 825, 539: 826, 414: 827, 335: 828, 628: 829, 467: 830, 388: 831, 470: 832, 686: 833, 656: 834, 382: 835, 349: 836, 375: 837, 816: 838, 430: 839, 691: 840, 340: 841, 241: 842, 477: 843, 739: 844, 704: 845, 48: 846, 777: 847, 522: 848, 461: 849, 873: 850, 31: 851, 517: 852, 261: 853, 808: 854, 598: 855, 219: 856, 196: 857, 140: 858, 220: 859, 681: 860, 607: 861, 729: 862, 93: 863, 599: 864, 726: 865, 441: 866, 331: 867, 556: 868, 482: 869, 696: 870, 930: 871, 762: 872, 494: 873, 413: 874, 898: 875, 51: 876, 799: 877, 424: 878, 98: 879, 857: 880, 209: 881, 926: 882, 861: 883, 736: 884, 278: 885, 575: 886, 202: 887, 572: 888, 602: 889, 685: 890, 273: 891, 153: 892, 813: 893, 228: 894, 353: 895, 317: 896, 893: 897, 444: 898, 309: 899, 793: 900, 652: 901, 111: 902, 732: 903, 304: 904, 134: 905, 34: 906, 86: 907, 471: 908, 225: 909, 769: 910, 260: 911, 302: 912, 469: 913, 820: 914, 183: 915, 636: 916, 421: 917, 443: 918, 858: 919, 516: 920, 672: 921, 765: 922, 891: 923, 581: 924, 282: 925, 226: 926, 415: 927, 801: 928, 78: 929, 824: 930, 744: 931, 888: 932, 155: 933, 713: 934, 242: 935, 814: 936, 594: 937, 866: 938, 855: 939, 47: 940, 565: 941, 132: 942}\n"
     ]
    }
   ],
   "source": [
    "user_ids = ratings_df[\"user_id\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "movie_ids = ratings_df[\"movie_id\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "ratings_df[\"user\"] = ratings_df[\"user_id\"].map(user2user_encoded)\n",
    "ratings_df[\"movie\"] = ratings_df[\"movie_id\"].map(movie2movie_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_encoded2movie)\n",
    "ratings_df[\"user_rating\"] = ratings_df[\"user_rating\"].values.astype(np.float32)\n",
    "ratings_df[\"like\"] = ratings_df[\"like\"].values.astype(np.float32)\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(ratings_df[\"user_rating\"])\n",
    "max_rating = max(ratings_df[\"user_rating\"])\n",
    "min_age = min(ratings_df[\"bucketized_user_age\"])\n",
    "max_age = max(ratings_df[\"bucketized_user_age\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")\n",
    "print(user2user_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 78  72]\n",
      " [502 174]\n",
      " [455  23]\n",
      " ...\n",
      " [884  79]\n",
      " [194 104]\n",
      " [527 178]] 40370    0.622459\n",
      "4348     0.622459\n",
      "1818     0.851953\n",
      "22939    0.880797\n",
      "42426    0.500000\n",
      "           ...   \n",
      "17073    0.622459\n",
      "2875     0.562177\n",
      "20452    0.622459\n",
      "3758     0.622459\n",
      "4845     0.880797\n",
      "Name: target, Length: 1000, dtype: float64\n",
      "Jumlah data train:  800\n",
      "Jumlah data val:  200\n"
     ]
    }
   ],
   "source": [
    "df = ratings_df.sample(frac=1, random_state=42)\n",
    "df = df.head(1000)\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "df[\"rating_norm\"] = df[\"user_rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "df[\"target\"] = df.apply(lambda row: sigmoid(row[\"rating_norm\"] + row[\"like\"]), axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Assuming training on 90% of the data and validating on 10%.\n",
    "train_indices = int(0.8 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")\n",
    "\n",
    "print(x, y)\n",
    "print(\"Jumlah data train: \", len(x_train))\n",
    "print(\"Jumlah data val: \", len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iskandar\\Documents\\GitHub\\nbs-ml\\venv-collab\\Lib\\site-packages\\keras\\src\\layers\\layer.py:361: UserWarning: `build()` was called on layer 'recommender_net_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"recommender_net_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1mModel: \"recommender_net_6\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                        \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m        Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_36 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_37 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_38 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_39 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 943, Num movies: 1682\n",
      "Embedding size: 50\n",
      "<Embedding name=embedding_36, built=False>\n",
      "<Embedding name=embedding_38, built=False>\n",
      "<Embedding name=embedding_37, built=False>\n",
      "<Embedding name=embedding_39, built=False>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.utils import register_keras_serializable\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "@register_keras_serializable()\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        return tf.nn.sigmoid(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RecommenderNet, self).get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_movies': self.num_movies,\n",
    "            'embedding_size': self.embedding_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "get_custom_objects().update({'RecommenderNet': RecommenderNet})\n",
    "\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.build(input_shape=(None, 2))\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    # metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(f'Num users: {num_users}, Num movies: {num_movies}')\n",
    "print(f'Embedding size: {EMBEDDING_SIZE}')\n",
    "print(model.user_embedding)\n",
    "print(model.movie_embedding)\n",
    "print(model.user_bias)\n",
    "print(model.movie_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 0.6694 - root_mean_squared_error: 0.2551 - val_loss: 0.5909 - val_root_mean_squared_error: 0.1599\n",
      "Epoch 2/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9392 - root_mean_squared_error: 0.2639 - val_loss: 0.6877 - val_root_mean_squared_error: 0.2737\n",
      "Epoch 3/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 1.0346 - root_mean_squared_error: 0.4758 - val_loss: 0.8089 - val_root_mean_squared_error: 0.3634\n",
      "Epoch 4/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 1.1169 - root_mean_squared_error: 0.2805 - val_loss: 0.8172 - val_root_mean_squared_error: 0.3692\n",
      "Epoch 5/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6135 - root_mean_squared_error: 0.1758 - val_loss: 0.7872 - val_root_mean_squared_error: 0.3500\n",
      "Epoch 6/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5918 - root_mean_squared_error: 0.1679 - val_loss: 0.7928 - val_root_mean_squared_error: 0.3536\n",
      "Epoch 7/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5936 - root_mean_squared_error: 0.1594 - val_loss: 0.7721 - val_root_mean_squared_error: 0.3397\n",
      "Epoch 8/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5930 - root_mean_squared_error: 0.1697 - val_loss: 0.7914 - val_root_mean_squared_error: 0.3527\n",
      "Epoch 9/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6071 - root_mean_squared_error: 0.1703 - val_loss: 0.7431 - val_root_mean_squared_error: 0.3187\n",
      "Epoch 10/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6173 - root_mean_squared_error: 0.2003 - val_loss: 0.8125 - val_root_mean_squared_error: 0.3661\n",
      "Epoch 11/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6955 - root_mean_squared_error: 0.2156 - val_loss: 0.7268 - val_root_mean_squared_error: 0.3062\n",
      "Epoch 12/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6246 - root_mean_squared_error: 0.2080 - val_loss: 0.8020 - val_root_mean_squared_error: 0.3598\n",
      "Epoch 13/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6886 - root_mean_squared_error: 0.2132 - val_loss: 0.7253 - val_root_mean_squared_error: 0.3050\n",
      "Epoch 14/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6109 - root_mean_squared_error: 0.1943 - val_loss: 0.7833 - val_root_mean_squared_error: 0.3472\n",
      "Epoch 15/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6378 - root_mean_squared_error: 0.1899 - val_loss: 0.7183 - val_root_mean_squared_error: 0.2993\n",
      "Epoch 16/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5990 - root_mean_squared_error: 0.1787 - val_loss: 0.7693 - val_root_mean_squared_error: 0.3375\n",
      "Epoch 17/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6141 - root_mean_squared_error: 0.1740 - val_loss: 0.7147 - val_root_mean_squared_error: 0.2963\n",
      "Epoch 18/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5922 - root_mean_squared_error: 0.1693 - val_loss: 0.7569 - val_root_mean_squared_error: 0.3286\n",
      "Epoch 19/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6076 - root_mean_squared_error: 0.1698 - val_loss: 0.7086 - val_root_mean_squared_error: 0.2913\n",
      "Epoch 20/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5858 - root_mean_squared_error: 0.1605 - val_loss: 0.7487 - val_root_mean_squared_error: 0.3225\n",
      "Epoch 21/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5962 - root_mean_squared_error: 0.1606 - val_loss: 0.7056 - val_root_mean_squared_error: 0.2887\n",
      "Epoch 22/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5860 - root_mean_squared_error: 0.1622 - val_loss: 0.7429 - val_root_mean_squared_error: 0.3182\n",
      "Epoch 23/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6003 - root_mean_squared_error: 0.1632 - val_loss: 0.6994 - val_root_mean_squared_error: 0.2835\n",
      "Epoch 24/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5823 - root_mean_squared_error: 0.1569 - val_loss: 0.7341 - val_root_mean_squared_error: 0.3115\n",
      "Epoch 25/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5948 - root_mean_squared_error: 0.1595 - val_loss: 0.6958 - val_root_mean_squared_error: 0.2804\n",
      "Epoch 26/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5824 - root_mean_squared_error: 0.1558 - val_loss: 0.7265 - val_root_mean_squared_error: 0.3055\n",
      "Epoch 27/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5895 - root_mean_squared_error: 0.1544 - val_loss: 0.6919 - val_root_mean_squared_error: 0.2770\n",
      "Epoch 28/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5765 - root_mean_squared_error: 0.1474 - val_loss: 0.7200 - val_root_mean_squared_error: 0.3004\n",
      "Epoch 29/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5817 - root_mean_squared_error: 0.1471 - val_loss: 0.6888 - val_root_mean_squared_error: 0.2743\n",
      "Epoch 30/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5743 - root_mean_squared_error: 0.1438 - val_loss: 0.7105 - val_root_mean_squared_error: 0.2927\n",
      "Epoch 31/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5785 - root_mean_squared_error: 0.1443 - val_loss: 0.6834 - val_root_mean_squared_error: 0.2695\n",
      "Epoch 32/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5737 - root_mean_squared_error: 0.1434 - val_loss: 0.7048 - val_root_mean_squared_error: 0.2879\n",
      "Epoch 33/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5756 - root_mean_squared_error: 0.1407 - val_loss: 0.6804 - val_root_mean_squared_error: 0.2668\n",
      "Epoch 34/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5712 - root_mean_squared_error: 0.1411 - val_loss: 0.6997 - val_root_mean_squared_error: 0.2837\n",
      "Epoch 35/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5761 - root_mean_squared_error: 0.1405 - val_loss: 0.6766 - val_root_mean_squared_error: 0.2634\n",
      "Epoch 36/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5733 - root_mean_squared_error: 0.1428 - val_loss: 0.6935 - val_root_mean_squared_error: 0.2783\n",
      "Epoch 37/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5762 - root_mean_squared_error: 0.1408 - val_loss: 0.6712 - val_root_mean_squared_error: 0.2583\n",
      "Epoch 38/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5728 - root_mean_squared_error: 0.1429 - val_loss: 0.6862 - val_root_mean_squared_error: 0.2719\n",
      "Epoch 39/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5754 - root_mean_squared_error: 0.1404 - val_loss: 0.6674 - val_root_mean_squared_error: 0.2548\n",
      "Epoch 40/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5698 - root_mean_squared_error: 0.1378 - val_loss: 0.6793 - val_root_mean_squared_error: 0.2658\n",
      "Epoch 41/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5718 - root_mean_squared_error: 0.1358 - val_loss: 0.6634 - val_root_mean_squared_error: 0.2509\n",
      "Epoch 42/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5666 - root_mean_squared_error: 0.1343 - val_loss: 0.6741 - val_root_mean_squared_error: 0.2611\n",
      "Epoch 43/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5693 - root_mean_squared_error: 0.1334 - val_loss: 0.6587 - val_root_mean_squared_error: 0.2464\n",
      "Epoch 44/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5659 - root_mean_squared_error: 0.1312 - val_loss: 0.6677 - val_root_mean_squared_error: 0.2550\n",
      "Epoch 45/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5663 - root_mean_squared_error: 0.1297 - val_loss: 0.6550 - val_root_mean_squared_error: 0.2428\n",
      "Epoch 46/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5657 - root_mean_squared_error: 0.1312 - val_loss: 0.6638 - val_root_mean_squared_error: 0.2513\n",
      "Epoch 47/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5670 - root_mean_squared_error: 0.1303 - val_loss: 0.6513 - val_root_mean_squared_error: 0.2391\n",
      "Epoch 48/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5661 - root_mean_squared_error: 0.1321 - val_loss: 0.6590 - val_root_mean_squared_error: 0.2467\n",
      "Epoch 49/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5659 - root_mean_squared_error: 0.1301 - val_loss: 0.6478 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 50/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5664 - root_mean_squared_error: 0.1336 - val_loss: 0.6539 - val_root_mean_squared_error: 0.2417\n",
      "Epoch 51/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5683 - root_mean_squared_error: 0.1322 - val_loss: 0.6434 - val_root_mean_squared_error: 0.2310\n",
      "Epoch 52/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5674 - root_mean_squared_error: 0.1337 - val_loss: 0.6478 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 53/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5674 - root_mean_squared_error: 0.1310 - val_loss: 0.6416 - val_root_mean_squared_error: 0.2292\n",
      "Epoch 54/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5669 - root_mean_squared_error: 0.1333 - val_loss: 0.6433 - val_root_mean_squared_error: 0.2309\n",
      "Epoch 55/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5666 - root_mean_squared_error: 0.1295 - val_loss: 0.6351 - val_root_mean_squared_error: 0.2222\n",
      "Epoch 56/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5645 - root_mean_squared_error: 0.1293 - val_loss: 0.6381 - val_root_mean_squared_error: 0.2255\n",
      "Epoch 57/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5640 - root_mean_squared_error: 0.1266 - val_loss: 0.6314 - val_root_mean_squared_error: 0.2182\n",
      "Epoch 58/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5628 - root_mean_squared_error: 0.1265 - val_loss: 0.6342 - val_root_mean_squared_error: 0.2213\n",
      "Epoch 59/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5613 - root_mean_squared_error: 0.1239 - val_loss: 0.6278 - val_root_mean_squared_error: 0.2142\n",
      "Epoch 60/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5610 - root_mean_squared_error: 0.1243 - val_loss: 0.6313 - val_root_mean_squared_error: 0.2182\n",
      "Epoch 61/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5618 - root_mean_squared_error: 0.1235 - val_loss: 0.6251 - val_root_mean_squared_error: 0.2113\n",
      "Epoch 62/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5603 - root_mean_squared_error: 0.1237 - val_loss: 0.6281 - val_root_mean_squared_error: 0.2146\n",
      "Epoch 63/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5617 - root_mean_squared_error: 0.1236 - val_loss: 0.6232 - val_root_mean_squared_error: 0.2091\n",
      "Epoch 64/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5623 - root_mean_squared_error: 0.1249 - val_loss: 0.6248 - val_root_mean_squared_error: 0.2109\n",
      "Epoch 65/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5627 - root_mean_squared_error: 0.1251 - val_loss: 0.6202 - val_root_mean_squared_error: 0.2057\n",
      "Epoch 66/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5625 - root_mean_squared_error: 0.1263 - val_loss: 0.6192 - val_root_mean_squared_error: 0.2046\n",
      "Epoch 67/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5638 - root_mean_squared_error: 0.1264 - val_loss: 0.6181 - val_root_mean_squared_error: 0.2032\n",
      "Epoch 68/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5653 - root_mean_squared_error: 0.1298 - val_loss: 0.6086 - val_root_mean_squared_error: 0.1919\n",
      "Epoch 69/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5663 - root_mean_squared_error: 0.1298 - val_loss: 0.6156 - val_root_mean_squared_error: 0.2003\n",
      "Epoch 70/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5662 - root_mean_squared_error: 0.1313 - val_loss: 0.5937 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 71/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5664 - root_mean_squared_error: 0.1299 - val_loss: 0.6137 - val_root_mean_squared_error: 0.1980\n",
      "Epoch 72/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5652 - root_mean_squared_error: 0.1296 - val_loss: 0.5865 - val_root_mean_squared_error: 0.1631\n",
      "Epoch 73/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5664 - root_mean_squared_error: 0.1287 - val_loss: 0.6081 - val_root_mean_squared_error: 0.1914\n",
      "Epoch 74/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5635 - root_mean_squared_error: 0.1270 - val_loss: 0.5899 - val_root_mean_squared_error: 0.1677\n",
      "Epoch 75/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5629 - root_mean_squared_error: 0.1259 - val_loss: 0.6038 - val_root_mean_squared_error: 0.1859\n",
      "Epoch 76/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5617 - root_mean_squared_error: 0.1240 - val_loss: 0.5840 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 77/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5630 - root_mean_squared_error: 0.1256 - val_loss: 0.5994 - val_root_mean_squared_error: 0.1804\n",
      "Epoch 78/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5610 - root_mean_squared_error: 0.1237 - val_loss: 0.5859 - val_root_mean_squared_error: 0.1623\n",
      "Epoch 79/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5628 - root_mean_squared_error: 0.1246 - val_loss: 0.5976 - val_root_mean_squared_error: 0.1780\n",
      "Epoch 80/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5612 - root_mean_squared_error: 0.1236 - val_loss: 0.5823 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 81/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5627 - root_mean_squared_error: 0.1251 - val_loss: 0.5971 - val_root_mean_squared_error: 0.1774\n",
      "Epoch 82/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5614 - root_mean_squared_error: 0.1243 - val_loss: 0.5739 - val_root_mean_squared_error: 0.1446\n",
      "Epoch 83/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5629 - root_mean_squared_error: 0.1256 - val_loss: 0.5937 - val_root_mean_squared_error: 0.1729\n",
      "Epoch 84/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5617 - root_mean_squared_error: 0.1241 - val_loss: 0.5687 - val_root_mean_squared_error: 0.1364\n",
      "Epoch 85/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5624 - root_mean_squared_error: 0.1244 - val_loss: 0.5906 - val_root_mean_squared_error: 0.1687\n",
      "Epoch 86/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5604 - root_mean_squared_error: 0.1227 - val_loss: 0.5676 - val_root_mean_squared_error: 0.1348\n",
      "Epoch 87/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5616 - root_mean_squared_error: 0.1234 - val_loss: 0.5897 - val_root_mean_squared_error: 0.1675\n",
      "Epoch 88/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5608 - root_mean_squared_error: 0.1230 - val_loss: 0.5668 - val_root_mean_squared_error: 0.1335\n",
      "Epoch 89/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5634 - root_mean_squared_error: 0.1252 - val_loss: 0.5893 - val_root_mean_squared_error: 0.1670\n",
      "Epoch 90/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5614 - root_mean_squared_error: 0.1247 - val_loss: 0.5664 - val_root_mean_squared_error: 0.1327\n",
      "Epoch 91/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5627 - root_mean_squared_error: 0.1239 - val_loss: 0.5881 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 92/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5616 - root_mean_squared_error: 0.1248 - val_loss: 0.5668 - val_root_mean_squared_error: 0.1335\n",
      "Epoch 93/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5614 - root_mean_squared_error: 0.1230 - val_loss: 0.5944 - val_root_mean_squared_error: 0.1738\n",
      "Epoch 94/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5651 - root_mean_squared_error: 0.1312 - val_loss: 0.5639 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 95/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5656 - root_mean_squared_error: 0.1287 - val_loss: 0.5967 - val_root_mean_squared_error: 0.1769\n",
      "Epoch 96/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5705 - root_mean_squared_error: 0.1387 - val_loss: 0.5593 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 97/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5730 - root_mean_squared_error: 0.1361 - val_loss: 0.6072 - val_root_mean_squared_error: 0.1903\n",
      "Epoch 98/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5800 - root_mean_squared_error: 0.1527 - val_loss: 0.5601 - val_root_mean_squared_error: 0.1218\n",
      "Epoch 99/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5780 - root_mean_squared_error: 0.1390 - val_loss: 0.6668 - val_root_mean_squared_error: 0.2541\n",
      "Epoch 100/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5817 - root_mean_squared_error: 0.1541 - val_loss: 0.5617 - val_root_mean_squared_error: 0.1237\n",
      "Epoch 101/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5948 - root_mean_squared_error: 0.1549 - val_loss: 0.7040 - val_root_mean_squared_error: 0.2866\n",
      "Epoch 102/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6309 - root_mean_squared_error: 0.2132 - val_loss: 0.5853 - val_root_mean_squared_error: 0.1481\n",
      "Epoch 103/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.8405 - root_mean_squared_error: 0.2430 - val_loss: 1.3645 - val_root_mean_squared_error: 0.5637\n",
      "Epoch 104/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 1.2583 - root_mean_squared_error: 0.4533 - val_loss: 0.9977 - val_root_mean_squared_error: 0.2636\n",
      "Epoch 105/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 1.3172 - root_mean_squared_error: 0.2674 - val_loss: 2.1196 - val_root_mean_squared_error: 0.6694\n",
      "Epoch 106/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 1.3569 - root_mean_squared_error: 0.5043 - val_loss: 0.7998 - val_root_mean_squared_error: 0.2330\n",
      "Epoch 107/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 2.9891 - root_mean_squared_error: 0.2945 - val_loss: 0.8750 - val_root_mean_squared_error: 0.3892\n",
      "Epoch 108/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6274 - root_mean_squared_error: 0.1927 - val_loss: 0.8629 - val_root_mean_squared_error: 0.3843\n",
      "Epoch 109/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6388 - root_mean_squared_error: 0.1866 - val_loss: 0.8718 - val_root_mean_squared_error: 0.3885\n",
      "Epoch 110/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6273 - root_mean_squared_error: 0.1826 - val_loss: 0.8809 - val_root_mean_squared_error: 0.3925\n",
      "Epoch 111/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6312 - root_mean_squared_error: 0.2056 - val_loss: 0.7722 - val_root_mean_squared_error: 0.3308\n",
      "Epoch 112/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.7384 - root_mean_squared_error: 0.2135 - val_loss: 1.5624 - val_root_mean_squared_error: 0.6052\n",
      "Epoch 113/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3774 - root_mean_squared_error: 0.5407 - val_loss: 0.6395 - val_root_mean_squared_error: 0.2244\n",
      "Epoch 114/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3911 - root_mean_squared_error: 0.2934 - val_loss: 0.7994 - val_root_mean_squared_error: 0.3470\n",
      "Epoch 115/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.9407 - root_mean_squared_error: 0.2603 - val_loss: 1.3993 - val_root_mean_squared_error: 0.5738\n",
      "Epoch 116/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.8833 - root_mean_squared_error: 0.3909 - val_loss: 0.7497 - val_root_mean_squared_error: 0.3157\n",
      "Epoch 117/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 1.0849 - root_mean_squared_error: 0.2709 - val_loss: 0.6451 - val_root_mean_squared_error: 0.2318\n",
      "Epoch 118/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5942 - root_mean_squared_error: 0.1565 - val_loss: 0.6375 - val_root_mean_squared_error: 0.2241\n",
      "Epoch 119/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5894 - root_mean_squared_error: 0.1566 - val_loss: 0.6451 - val_root_mean_squared_error: 0.2320\n",
      "Epoch 120/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5995 - root_mean_squared_error: 0.1584 - val_loss: 0.6394 - val_root_mean_squared_error: 0.2263\n",
      "Epoch 121/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5888 - root_mean_squared_error: 0.1622 - val_loss: 0.6484 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 122/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6143 - root_mean_squared_error: 0.1761 - val_loss: 0.6282 - val_root_mean_squared_error: 0.2150\n",
      "Epoch 123/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6422 - root_mean_squared_error: 0.2272 - val_loss: 0.6684 - val_root_mean_squared_error: 0.2546\n",
      "Epoch 124/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.7467 - root_mean_squared_error: 0.2203 - val_loss: 0.6150 - val_root_mean_squared_error: 0.1994\n",
      "Epoch 125/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6961 - root_mean_squared_error: 0.2706 - val_loss: 0.6807 - val_root_mean_squared_error: 0.2651\n",
      "Epoch 126/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8715 - root_mean_squared_error: 0.2520 - val_loss: 0.6157 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 127/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6214 - root_mean_squared_error: 0.2039 - val_loss: 0.6305 - val_root_mean_squared_error: 0.2176\n",
      "Epoch 128/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6399 - root_mean_squared_error: 0.1805 - val_loss: 0.6013 - val_root_mean_squared_error: 0.1832\n",
      "Epoch 129/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6300 - root_mean_squared_error: 0.2155 - val_loss: 0.6414 - val_root_mean_squared_error: 0.2289\n",
      "Epoch 130/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.7242 - root_mean_squared_error: 0.2163 - val_loss: 0.5978 - val_root_mean_squared_error: 0.1789\n",
      "Epoch 131/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6252 - root_mean_squared_error: 0.2094 - val_loss: 0.6265 - val_root_mean_squared_error: 0.2133\n",
      "Epoch 132/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6793 - root_mean_squared_error: 0.2008 - val_loss: 0.5967 - val_root_mean_squared_error: 0.1775\n",
      "Epoch 133/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6215 - root_mean_squared_error: 0.2061 - val_loss: 0.6209 - val_root_mean_squared_error: 0.2072\n",
      "Epoch 134/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6748 - root_mean_squared_error: 0.1985 - val_loss: 0.5920 - val_root_mean_squared_error: 0.1716\n",
      "Epoch 135/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6141 - root_mean_squared_error: 0.1986 - val_loss: 0.6175 - val_root_mean_squared_error: 0.2034\n",
      "Epoch 136/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6356 - root_mean_squared_error: 0.1790 - val_loss: 0.5926 - val_root_mean_squared_error: 0.1724\n",
      "Epoch 137/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5979 - root_mean_squared_error: 0.1777 - val_loss: 0.6101 - val_root_mean_squared_error: 0.1947\n",
      "Epoch 138/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6258 - root_mean_squared_error: 0.1745 - val_loss: 0.5878 - val_root_mean_squared_error: 0.1660\n",
      "Epoch 139/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6002 - root_mean_squared_error: 0.1812 - val_loss: 0.6069 - val_root_mean_squared_error: 0.1909\n",
      "Epoch 140/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6276 - root_mean_squared_error: 0.1758 - val_loss: 0.5855 - val_root_mean_squared_error: 0.1628\n",
      "Epoch 141/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5958 - root_mean_squared_error: 0.1746 - val_loss: 0.6047 - val_root_mean_squared_error: 0.1882\n",
      "Epoch 142/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6326 - root_mean_squared_error: 0.1809 - val_loss: 0.5836 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 143/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6060 - root_mean_squared_error: 0.1884 - val_loss: 0.6018 - val_root_mean_squared_error: 0.1846\n",
      "Epoch 144/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6274 - root_mean_squared_error: 0.1753 - val_loss: 0.5837 - val_root_mean_squared_error: 0.1603\n",
      "Epoch 145/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5867 - root_mean_squared_error: 0.1633 - val_loss: 0.5980 - val_root_mean_squared_error: 0.1797\n",
      "Epoch 146/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5998 - root_mean_squared_error: 0.1592 - val_loss: 0.5836 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 147/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5831 - root_mean_squared_error: 0.1597 - val_loss: 0.5970 - val_root_mean_squared_error: 0.1784\n",
      "Epoch 148/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5961 - root_mean_squared_error: 0.1551 - val_loss: 0.5840 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 149/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5836 - root_mean_squared_error: 0.1592 - val_loss: 0.5972 - val_root_mean_squared_error: 0.1786\n",
      "Epoch 150/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6008 - root_mean_squared_error: 0.1597 - val_loss: 0.5813 - val_root_mean_squared_error: 0.1566\n",
      "Epoch 151/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5936 - root_mean_squared_error: 0.1737 - val_loss: 0.5966 - val_root_mean_squared_error: 0.1778\n",
      "Epoch 152/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6188 - root_mean_squared_error: 0.1726 - val_loss: 0.5806 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 153/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5891 - root_mean_squared_error: 0.1673 - val_loss: 0.5933 - val_root_mean_squared_error: 0.1734\n",
      "Epoch 154/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6117 - root_mean_squared_error: 0.1683 - val_loss: 0.5806 - val_root_mean_squared_error: 0.1555\n",
      "Epoch 155/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5853 - root_mean_squared_error: 0.1614 - val_loss: 0.5887 - val_root_mean_squared_error: 0.1671\n",
      "Epoch 156/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5961 - root_mean_squared_error: 0.1569 - val_loss: 0.5781 - val_root_mean_squared_error: 0.1518\n",
      "Epoch 157/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5765 - root_mean_squared_error: 0.1496 - val_loss: 0.5866 - val_root_mean_squared_error: 0.1641\n",
      "Epoch 158/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5816 - root_mean_squared_error: 0.1448 - val_loss: 0.5786 - val_root_mean_squared_error: 0.1525\n",
      "Epoch 159/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5750 - root_mean_squared_error: 0.1475 - val_loss: 0.5856 - val_root_mean_squared_error: 0.1626\n",
      "Epoch 160/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5851 - root_mean_squared_error: 0.1475 - val_loss: 0.5778 - val_root_mean_squared_error: 0.1513\n",
      "Epoch 161/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5793 - root_mean_squared_error: 0.1519 - val_loss: 0.5850 - val_root_mean_squared_error: 0.1618\n",
      "Epoch 162/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5841 - root_mean_squared_error: 0.1463 - val_loss: 0.5776 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 163/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5738 - root_mean_squared_error: 0.1441 - val_loss: 0.5833 - val_root_mean_squared_error: 0.1593\n",
      "Epoch 164/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5786 - root_mean_squared_error: 0.1414 - val_loss: 0.5757 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 165/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5746 - root_mean_squared_error: 0.1458 - val_loss: 0.5811 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 166/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5813 - root_mean_squared_error: 0.1447 - val_loss: 0.5750 - val_root_mean_squared_error: 0.1468\n",
      "Epoch 167/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5763 - root_mean_squared_error: 0.1477 - val_loss: 0.5799 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 168/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5824 - root_mean_squared_error: 0.1449 - val_loss: 0.5742 - val_root_mean_squared_error: 0.1455\n",
      "Epoch 169/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5725 - root_mean_squared_error: 0.1424 - val_loss: 0.5783 - val_root_mean_squared_error: 0.1517\n",
      "Epoch 170/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5768 - root_mean_squared_error: 0.1400 - val_loss: 0.5737 - val_root_mean_squared_error: 0.1448\n",
      "Epoch 171/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5688 - root_mean_squared_error: 0.1368 - val_loss: 0.5767 - val_root_mean_squared_error: 0.1493\n",
      "Epoch 172/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5714 - root_mean_squared_error: 0.1339 - val_loss: 0.5732 - val_root_mean_squared_error: 0.1440\n",
      "Epoch 173/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5646 - root_mean_squared_error: 0.1300 - val_loss: 0.5753 - val_root_mean_squared_error: 0.1472\n",
      "Epoch 174/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5666 - root_mean_squared_error: 0.1293 - val_loss: 0.5727 - val_root_mean_squared_error: 0.1432\n",
      "Epoch 175/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5633 - root_mean_squared_error: 0.1284 - val_loss: 0.5749 - val_root_mean_squared_error: 0.1465\n",
      "Epoch 176/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5659 - root_mean_squared_error: 0.1285 - val_loss: 0.5720 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 177/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5643 - root_mean_squared_error: 0.1304 - val_loss: 0.5741 - val_root_mean_squared_error: 0.1453\n",
      "Epoch 178/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5672 - root_mean_squared_error: 0.1300 - val_loss: 0.5715 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 179/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5670 - root_mean_squared_error: 0.1333 - val_loss: 0.5734 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 180/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5716 - root_mean_squared_error: 0.1349 - val_loss: 0.5708 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 181/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5695 - root_mean_squared_error: 0.1376 - val_loss: 0.5710 - val_root_mean_squared_error: 0.1405\n",
      "Epoch 182/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5717 - root_mean_squared_error: 0.1355 - val_loss: 0.5708 - val_root_mean_squared_error: 0.1401\n",
      "Epoch 183/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5672 - root_mean_squared_error: 0.1332 - val_loss: 0.5702 - val_root_mean_squared_error: 0.1391\n",
      "Epoch 184/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5674 - root_mean_squared_error: 0.1306 - val_loss: 0.5699 - val_root_mean_squared_error: 0.1386\n",
      "Epoch 185/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5626 - root_mean_squared_error: 0.1265 - val_loss: 0.5699 - val_root_mean_squared_error: 0.1387\n",
      "Epoch 186/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5620 - root_mean_squared_error: 0.1242 - val_loss: 0.5690 - val_root_mean_squared_error: 0.1371\n",
      "Epoch 187/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5610 - root_mean_squared_error: 0.1229 - val_loss: 0.5693 - val_root_mean_squared_error: 0.1376\n",
      "Epoch 188/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5598 - root_mean_squared_error: 0.1204 - val_loss: 0.5688 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 189/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5593 - root_mean_squared_error: 0.1205 - val_loss: 0.5692 - val_root_mean_squared_error: 0.1375\n",
      "Epoch 190/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5592 - root_mean_squared_error: 0.1194 - val_loss: 0.5687 - val_root_mean_squared_error: 0.1365\n",
      "Epoch 191/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5582 - root_mean_squared_error: 0.1200 - val_loss: 0.5692 - val_root_mean_squared_error: 0.1374\n",
      "Epoch 192/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5587 - root_mean_squared_error: 0.1196 - val_loss: 0.5686 - val_root_mean_squared_error: 0.1364\n",
      "Epoch 193/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5604 - root_mean_squared_error: 0.1220 - val_loss: 0.5690 - val_root_mean_squared_error: 0.1370\n",
      "Epoch 194/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5616 - root_mean_squared_error: 0.1226 - val_loss: 0.5684 - val_root_mean_squared_error: 0.1360\n",
      "Epoch 195/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5618 - root_mean_squared_error: 0.1249 - val_loss: 0.5674 - val_root_mean_squared_error: 0.1344\n",
      "Epoch 196/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5667 - root_mean_squared_error: 0.1288 - val_loss: 0.5689 - val_root_mean_squared_error: 0.1368\n",
      "Epoch 197/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5666 - root_mean_squared_error: 0.1329 - val_loss: 0.5642 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 198/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5681 - root_mean_squared_error: 0.1321 - val_loss: 0.5722 - val_root_mean_squared_error: 0.1420\n",
      "Epoch 199/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5650 - root_mean_squared_error: 0.1305 - val_loss: 0.5615 - val_root_mean_squared_error: 0.1246\n",
      "Epoch 200/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5647 - root_mean_squared_error: 0.1273 - val_loss: 0.5673 - val_root_mean_squared_error: 0.1343\n",
      "Epoch 201/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5609 - root_mean_squared_error: 0.1237 - val_loss: 0.5640 - val_root_mean_squared_error: 0.1289\n",
      "Epoch 202/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5583 - root_mean_squared_error: 0.1185 - val_loss: 0.5650 - val_root_mean_squared_error: 0.1305\n",
      "Epoch 203/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5566 - root_mean_squared_error: 0.1167 - val_loss: 0.5646 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 204/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5568 - root_mean_squared_error: 0.1162 - val_loss: 0.5646 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 205/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5566 - root_mean_squared_error: 0.1162 - val_loss: 0.5646 - val_root_mean_squared_error: 0.1298\n",
      "Epoch 206/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5563 - root_mean_squared_error: 0.1163 - val_loss: 0.5646 - val_root_mean_squared_error: 0.1299\n",
      "Epoch 207/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5569 - root_mean_squared_error: 0.1160 - val_loss: 0.5645 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 208/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5556 - root_mean_squared_error: 0.1156 - val_loss: 0.5644 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 209/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5565 - root_mean_squared_error: 0.1160 - val_loss: 0.5644 - val_root_mean_squared_error: 0.1295\n",
      "Epoch 210/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5571 - root_mean_squared_error: 0.1161 - val_loss: 0.5644 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 211/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5574 - root_mean_squared_error: 0.1163 - val_loss: 0.5644 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 212/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5560 - root_mean_squared_error: 0.1159 - val_loss: 0.5642 - val_root_mean_squared_error: 0.1291\n",
      "Epoch 213/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5572 - root_mean_squared_error: 0.1158 - val_loss: 0.5642 - val_root_mean_squared_error: 0.1292\n",
      "Epoch 214/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5582 - root_mean_squared_error: 0.1177 - val_loss: 0.5641 - val_root_mean_squared_error: 0.1290\n",
      "Epoch 215/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5586 - root_mean_squared_error: 0.1200 - val_loss: 0.5619 - val_root_mean_squared_error: 0.1253\n",
      "Epoch 216/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5637 - root_mean_squared_error: 0.1257 - val_loss: 0.5863 - val_root_mean_squared_error: 0.1627\n",
      "Epoch 217/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5711 - root_mean_squared_error: 0.1404 - val_loss: 0.5638 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 218/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5681 - root_mean_squared_error: 0.1315 - val_loss: 0.5848 - val_root_mean_squared_error: 0.1607\n",
      "Epoch 219/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5684 - root_mean_squared_error: 0.1366 - val_loss: 0.5629 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 220/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5713 - root_mean_squared_error: 0.1344 - val_loss: 0.5828 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 221/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5650 - root_mean_squared_error: 0.1301 - val_loss: 0.5591 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 222/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5628 - root_mean_squared_error: 0.1255 - val_loss: 0.5764 - val_root_mean_squared_error: 0.1484\n",
      "Epoch 223/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5672 - root_mean_squared_error: 0.1329 - val_loss: 0.5622 - val_root_mean_squared_error: 0.1245\n",
      "Epoch 224/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5701 - root_mean_squared_error: 0.1343 - val_loss: 0.5827 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 225/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5687 - root_mean_squared_error: 0.1361 - val_loss: 0.5600 - val_root_mean_squared_error: 0.1214\n",
      "Epoch 226/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5711 - root_mean_squared_error: 0.1346 - val_loss: 0.5813 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 227/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5741 - root_mean_squared_error: 0.1437 - val_loss: 0.5683 - val_root_mean_squared_error: 0.1321\n",
      "Epoch 228/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5818 - root_mean_squared_error: 0.1447 - val_loss: 0.5952 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 229/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5961 - root_mean_squared_error: 0.1744 - val_loss: 0.5946 - val_root_mean_squared_error: 0.1581\n",
      "Epoch 230/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6343 - root_mean_squared_error: 0.1783 - val_loss: 0.6393 - val_root_mean_squared_error: 0.2269\n",
      "Epoch 231/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6434 - root_mean_squared_error: 0.2224 - val_loss: 0.6163 - val_root_mean_squared_error: 0.1728\n",
      "Epoch 232/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.6533 - root_mean_squared_error: 0.1794 - val_loss: 0.8052 - val_root_mean_squared_error: 0.3576\n",
      "Epoch 233/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6437 - root_mean_squared_error: 0.2194 - val_loss: 0.5772 - val_root_mean_squared_error: 0.1471\n",
      "Epoch 234/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.7595 - root_mean_squared_error: 0.2207 - val_loss: 1.5745 - val_root_mean_squared_error: 0.6159\n",
      "Epoch 235/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 1.1090 - root_mean_squared_error: 0.4161 - val_loss: 0.8662 - val_root_mean_squared_error: 0.2529\n",
      "Epoch 236/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1891 - root_mean_squared_error: 0.2623 - val_loss: 2.1791 - val_root_mean_squared_error: 0.6903\n",
      "Epoch 237/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1658 - root_mean_squared_error: 0.4445 - val_loss: 0.6101 - val_root_mean_squared_error: 0.1635\n",
      "Epoch 238/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.5164 - root_mean_squared_error: 0.2863 - val_loss: 3.6965 - val_root_mean_squared_error: 0.7435\n",
      "Epoch 239/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.2395 - root_mean_squared_error: 0.6051 - val_loss: 0.8454 - val_root_mean_squared_error: 0.2435\n",
      "Epoch 240/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.5347 - root_mean_squared_error: 0.2930 - val_loss: 0.7286 - val_root_mean_squared_error: 0.3017\n",
      "Epoch 241/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6876 - root_mean_squared_error: 0.2000 - val_loss: 1.1256 - val_root_mean_squared_error: 0.4957\n",
      "Epoch 242/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.8548 - root_mean_squared_error: 0.3610 - val_loss: 0.7121 - val_root_mean_squared_error: 0.2904\n",
      "Epoch 243/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1835 - root_mean_squared_error: 0.2800 - val_loss: 0.6284 - val_root_mean_squared_error: 0.2149\n",
      "Epoch 244/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6386 - root_mean_squared_error: 0.2225 - val_loss: 0.6397 - val_root_mean_squared_error: 0.2269\n",
      "Epoch 245/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7678 - root_mean_squared_error: 0.2203 - val_loss: 0.6010 - val_root_mean_squared_error: 0.1824\n",
      "Epoch 246/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.7728 - root_mean_squared_error: 0.3278 - val_loss: 0.6551 - val_root_mean_squared_error: 0.2420\n",
      "Epoch 247/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.9955 - root_mean_squared_error: 0.2657 - val_loss: 0.6013 - val_root_mean_squared_error: 0.1835\n",
      "Epoch 248/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.5832 - root_mean_squared_error: 0.1515 - val_loss: 0.5974 - val_root_mean_squared_error: 0.1786\n",
      "Epoch 249/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.5947 - root_mean_squared_error: 0.1596 - val_loss: 0.5947 - val_root_mean_squared_error: 0.1751\n",
      "Epoch 250/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.6143 - root_mean_squared_error: 0.1897 - val_loss: 0.5956 - val_root_mean_squared_error: 0.1761\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=1024,\n",
    "    epochs=250,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m45/45\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Showing recommendations for user: 1\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "19 : Antonia's Line (1995)\n",
      "208 : Young Frankenstein (1974)\n",
      "137 : Big Night (1996)\n",
      "16 : French Twist (Gazon maudit) (1995)\n",
      "198 : Nikita (La Femme Nikita) (1990)\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "357 : One Flew Over the Cuckoo's Nest (1975)\n",
      "1650 : Butcher Boy, The (1998)\n",
      "1080 : Celestial Clockwork (1994)\n",
      "1398 : Anna (1996)\n",
      "1536 : Aiqing wansui (1994)\n",
      "1642 : Some Mother's Son (1996)\n",
      "1639 : Bitter Sugar (Azucar Amargo) (1996)\n",
      "1293 : Star Kid (1997)\n",
      "1458 : Damsel in Distress, A (1937)\n",
      "1636 : Brothers in Trouble (1995)\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan data frame dengan movieId unik\n",
    "movie_df = ratings_df[['movie_id']].drop_duplicates()\n",
    "\n",
    "# Memilih satu user secara acak\n",
    "user_id = 1\n",
    "movies_watched_by_user = df[df.user_id == user_id]\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df[\"movie_id\"].isin(movies_watched_by_user.movie_id.values)\n",
    "][\"movie_id\"]\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    ")\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    ")\n",
    "\n",
    "ratings = model.predict(user_movie_array).flatten()\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "print(\"====\" * 9)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"user_rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movie_id.values\n",
    ")\n",
    "movie_df_rows = movie_df[movie_df[\"movie_id\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.movie_id, \":\", ratings_df[ratings_df[\"movie_id\"] == row.movie_id][\"movie_title\"].values[0])  # Asumsikan ada kolom 'genres' di movie_df\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "recommended_movies = movie_df[movie_df[\"movie_id\"].isin(recommended_movie_ids)]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.movie_id, \":\", ratings_df[ratings_df[\"movie_id\"] == row.movie_id][\"movie_title\"].values[0])  # Asumsikan ada kolom 'genres' di movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "folder = './model'\n",
    "if not os.path.exists(folder):\n",
    "  os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open(folder + '/df.pkl', 'wb'))\n",
    "pickle.dump(user2user_encoded, open(folder + '/user_id_encoded.pkl', 'wb'))\n",
    "pickle.dump(movie2movie_encoded, open(folder + '/movie_id_encoded.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>raw_user_age</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "      <th>like</th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating_norm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "      <td>Money Talks (1997)</td>\n",
       "      <td>19.0</td>\n",
       "      <td>874815542</td>\n",
       "      <td>True</td>\n",
       "      <td>817</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>904</td>\n",
       "      <td>998</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.851953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80184</th>\n",
       "      <td>35.0</td>\n",
       "      <td>4</td>\n",
       "      <td>580</td>\n",
       "      <td>Englishman Who Went Up a Hill, But Came Down a...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>883869630</td>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>485</td>\n",
       "      <td>647</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.851953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>35.0</td>\n",
       "      <td>4</td>\n",
       "      <td>393</td>\n",
       "      <td>Mrs. Doubtfire (1993)</td>\n",
       "      <td>44.0</td>\n",
       "      <td>880088717</td>\n",
       "      <td>False</td>\n",
       "      <td>389</td>\n",
       "      <td>21</td>\n",
       "      <td>writer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134</td>\n",
       "      <td>388</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76699</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>Outbreak (1995)</td>\n",
       "      <td>30.0</td>\n",
       "      <td>888556814</td>\n",
       "      <td>True</td>\n",
       "      <td>774</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>392</td>\n",
       "      <td>580</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.731059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92991</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>420</td>\n",
       "      <td>Alice in Wonderland (1951)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>874957140</td>\n",
       "      <td>False</td>\n",
       "      <td>712</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>341</td>\n",
       "      <td>170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>35.0</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>Phenomenon (1996)</td>\n",
       "      <td>39.0</td>\n",
       "      <td>885852817</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>engineer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141</td>\n",
       "      <td>39</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>Reservoir Dogs (1992)</td>\n",
       "      <td>51.0</td>\n",
       "      <td>891397819</td>\n",
       "      <td>False</td>\n",
       "      <td>704</td>\n",
       "      <td>10</td>\n",
       "      <td>librarian</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>520</td>\n",
       "      <td>675</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>288</td>\n",
       "      <td>Scream (1996)</td>\n",
       "      <td>26.0</td>\n",
       "      <td>875129640</td>\n",
       "      <td>True</td>\n",
       "      <td>422</td>\n",
       "      <td>5</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>394</td>\n",
       "      <td>162</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>18.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>Monty Python and the Holy Grail (1974)</td>\n",
       "      <td>21.0</td>\n",
       "      <td>884207654</td>\n",
       "      <td>False</td>\n",
       "      <td>198</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176</td>\n",
       "      <td>508</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.679179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>864</td>\n",
       "      <td>My Fellow Americans (1996)</td>\n",
       "      <td>26.0</td>\n",
       "      <td>878962774</td>\n",
       "      <td>True</td>\n",
       "      <td>181</td>\n",
       "      <td>6</td>\n",
       "      <td>executive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>477</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.562177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bucketized_user_age  movie_genres  movie_id  \\\n",
       "75721                 18.0             0       876   \n",
       "80184                 35.0             4       580   \n",
       "19864                 35.0             4       393   \n",
       "76699                 25.0             0        54   \n",
       "92991                 18.0             2       420   \n",
       "...                    ...           ...       ...   \n",
       "6265                  35.0             7       125   \n",
       "54886                 50.0             5       156   \n",
       "76820                 25.0            10       288   \n",
       "860                   18.0             4       168   \n",
       "15795                 25.0             4       864   \n",
       "\n",
       "                                             movie_title  raw_user_age  \\\n",
       "75721                                 Money Talks (1997)          19.0   \n",
       "80184  Englishman Who Went Up a Hill, But Came Down a...          40.0   \n",
       "19864                              Mrs. Doubtfire (1993)          44.0   \n",
       "76699                                    Outbreak (1995)          30.0   \n",
       "92991                         Alice in Wonderland (1951)          22.0   \n",
       "...                                                  ...           ...   \n",
       "6265                                   Phenomenon (1996)          39.0   \n",
       "54886                              Reservoir Dogs (1992)          51.0   \n",
       "76820                                      Scream (1996)          26.0   \n",
       "860               Monty Python and the Holy Grail (1974)          21.0   \n",
       "15795                         My Fellow Americans (1996)          26.0   \n",
       "\n",
       "       timestamp  user_gender  user_id  user_occupation_label  \\\n",
       "75721  874815542         True      817                     17   \n",
       "80184  883869630         True       83                     11   \n",
       "19864  880088717        False      389                     21   \n",
       "76699  888556814         True      774                     17   \n",
       "92991  874957140        False      712                     17   \n",
       "...          ...          ...      ...                    ...   \n",
       "6265   885852817         True       25                     18   \n",
       "54886  891397819        False      704                     10   \n",
       "76820  875129640         True      422                      5   \n",
       "860    884207654        False      198                     17   \n",
       "15795  878962774         True      181                      6   \n",
       "\n",
       "      user_occupation_text  user_rating user_zip_code  like  user  movie  \\\n",
       "75721              student          4.0         60152   1.0   904    998   \n",
       "80184                other          4.0         44133   1.0   485    647   \n",
       "19864               writer          2.0         83702   1.0   134    388   \n",
       "76699              student          1.0         80027   1.0   392    580   \n",
       "92991              student          3.0         54901   1.0   341    170   \n",
       "...                    ...          ...           ...   ...   ...    ...   \n",
       "6265              engineer          5.0         55107   1.0   141     39   \n",
       "54886            librarian          3.0         91105   1.0   520    675   \n",
       "76820        entertainment          3.0         94533   1.0   394    162   \n",
       "860                student          4.0         55414   0.0   176    508   \n",
       "15795            executive          2.0         21218   0.0   171    477   \n",
       "\n",
       "       rating_norm    target  \n",
       "75721         0.75  0.851953  \n",
       "80184         0.75  0.851953  \n",
       "19864         0.25  0.777300  \n",
       "76699         0.00  0.731059  \n",
       "92991         0.50  0.817574  \n",
       "...            ...       ...  \n",
       "6265          1.00  0.880797  \n",
       "54886         0.50  0.817574  \n",
       "76820         0.50  0.817574  \n",
       "860           0.75  0.679179  \n",
       "15795         0.25  0.562177  \n",
       "\n",
       "[100000 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load(open(folder + '/df.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder + '/model_collab.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>raw_user_age</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "      <th>like</th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating_norm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "      <td>Money Talks (1997)</td>\n",
       "      <td>19.0</td>\n",
       "      <td>874815542</td>\n",
       "      <td>True</td>\n",
       "      <td>817</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>904</td>\n",
       "      <td>998</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.851953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80184</th>\n",
       "      <td>35.0</td>\n",
       "      <td>4</td>\n",
       "      <td>580</td>\n",
       "      <td>Englishman Who Went Up a Hill, But Came Down a...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>883869630</td>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>485</td>\n",
       "      <td>647</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.851953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>35.0</td>\n",
       "      <td>4</td>\n",
       "      <td>393</td>\n",
       "      <td>Mrs. Doubtfire (1993)</td>\n",
       "      <td>44.0</td>\n",
       "      <td>880088717</td>\n",
       "      <td>False</td>\n",
       "      <td>389</td>\n",
       "      <td>21</td>\n",
       "      <td>writer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134</td>\n",
       "      <td>388</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76699</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>Outbreak (1995)</td>\n",
       "      <td>30.0</td>\n",
       "      <td>888556814</td>\n",
       "      <td>True</td>\n",
       "      <td>774</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>392</td>\n",
       "      <td>580</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.731059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92991</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>420</td>\n",
       "      <td>Alice in Wonderland (1951)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>874957140</td>\n",
       "      <td>False</td>\n",
       "      <td>712</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>341</td>\n",
       "      <td>170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bucketized_user_age  movie_genres  movie_id  \\\n",
       "75721                 18.0             0       876   \n",
       "80184                 35.0             4       580   \n",
       "19864                 35.0             4       393   \n",
       "76699                 25.0             0        54   \n",
       "92991                 18.0             2       420   \n",
       "\n",
       "                                             movie_title  raw_user_age  \\\n",
       "75721                                 Money Talks (1997)          19.0   \n",
       "80184  Englishman Who Went Up a Hill, But Came Down a...          40.0   \n",
       "19864                              Mrs. Doubtfire (1993)          44.0   \n",
       "76699                                    Outbreak (1995)          30.0   \n",
       "92991                         Alice in Wonderland (1951)          22.0   \n",
       "\n",
       "       timestamp  user_gender  user_id  user_occupation_label  \\\n",
       "75721  874815542         True      817                     17   \n",
       "80184  883869630         True       83                     11   \n",
       "19864  880088717        False      389                     21   \n",
       "76699  888556814         True      774                     17   \n",
       "92991  874957140        False      712                     17   \n",
       "\n",
       "      user_occupation_text  user_rating user_zip_code  like  user  movie  \\\n",
       "75721              student          4.0         60152   1.0   904    998   \n",
       "80184                other          4.0         44133   1.0   485    647   \n",
       "19864               writer          2.0         83702   1.0   134    388   \n",
       "76699              student          1.0         80027   1.0   392    580   \n",
       "92991              student          3.0         54901   1.0   341    170   \n",
       "\n",
       "       rating_norm    target  \n",
       "75721         0.75  0.851953  \n",
       "80184         0.75  0.851953  \n",
       "19864         0.25  0.777300  \n",
       "76699         0.00  0.731059  \n",
       "92991         0.50  0.817574  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iskandar\\Documents\\GitHub\\nbs-ml\\venv-collab\\Lib\\site-packages\\keras\\src\\layers\\layer.py:361: UserWarning: `build()` was called on layer 'recommender_net_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"recommender_net_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1mModel: \"recommender_net_11\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                        \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m        Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_48 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_49 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_50 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_51 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_27 (\u001B[38;5;33mDense\u001B[0m)                     │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_28 (\u001B[38;5;33mDense\u001B[0m)                     │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_29 (\u001B[38;5;33mDense\u001B[0m)                     │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_30 (\u001B[38;5;33mDense\u001B[0m)                     │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 943, Num movies: 1682\n",
      "Embedding size: 50\n",
      "<Embedding name=embedding_48, built=False>\n",
      "<Embedding name=embedding_50, built=False>\n",
      "<Embedding name=embedding_49, built=False>\n",
      "<Embedding name=embedding_51, built=False>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.utils import register_keras_serializable\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "        self.dense1 = layers.Dense(32, activation='relu')\n",
    "        self.dense2 = layers.Dense(64, activation='relu')\n",
    "        self.dense3 = layers.Dense(128, activation='relu')\n",
    "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.output_layer(x)\n",
    "        # rating_output = tf.nn.sigmoid(x)\n",
    "        # like_output = tf.nn.sigmoid(x)\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return x\n",
    "\n",
    "\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.build(input_shape=(None, 2))\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    # metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(f'Num users: {num_users}, Num movies: {num_movies}')\n",
    "print(f'Embedding size: {EMBEDDING_SIZE}')\n",
    "print(model.user_embedding)\n",
    "print(model.movie_embedding)\n",
    "print(model.user_bias)\n",
    "print(model.movie_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - loss: 0.5818 - root_mean_squared_error: 0.1242 - val_loss: 0.5711 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 2/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5710 - root_mean_squared_error: 0.1049 - val_loss: 0.5708 - val_root_mean_squared_error: 0.1045\n",
      "Epoch 3/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5705 - root_mean_squared_error: 0.1048 - val_loss: 0.5706 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 4/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5711 - root_mean_squared_error: 0.1044 - val_loss: 0.5706 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 5/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5698 - root_mean_squared_error: 0.1040 - val_loss: 0.5705 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 6/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5700 - root_mean_squared_error: 0.1032 - val_loss: 0.5705 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 7/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5694 - root_mean_squared_error: 0.1028 - val_loss: 0.5709 - val_root_mean_squared_error: 0.1042\n",
      "Epoch 8/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5703 - root_mean_squared_error: 0.1031 - val_loss: 0.5705 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 9/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5694 - root_mean_squared_error: 0.1023 - val_loss: 0.5705 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 10/50\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 0.5701 - root_mean_squared_error: 0.1020 - val_loss: 0.5705 - val_root_mean_squared_error: 0.1036\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m46/46\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Showing recommendations for user: 49\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "433 : Heathers (1989)\n",
      "175 : Brazil (1985)\n",
      "428 : Harold and Maude (1971)\n",
      "209 : This Is Spinal Tap (1984)\n",
      "47 : Ed Wood (1994)\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "265 : Hunt for Red October, The (1990)\n",
      "285 : Secrets & Lies (1996)\n",
      "269 : Full Monty, The (1997)\n",
      "272 : Good Will Hunting (1997)\n",
      "64 : Shawshank Redemption, The (1994)\n",
      "251 : Shall We Dance? (1996)\n",
      "318 : Schindler's List (1993)\n",
      "316 : As Good As It Gets (1997)\n",
      "943 : Killing Zoe (1994)\n",
      "60 : Three Colors: Blue (1993)\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan data frame dengan movieId unik\n",
    "movie_df = ratings_df[['movie_id']].drop_duplicates()\n",
    "\n",
    "# Memilih satu user secara acak\n",
    "user_id = df.user_id.sample(1).iloc[0]\n",
    "movies_watched_by_user = df[df.user_id == user_id]\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df[\"movie_id\"].isin(movies_watched_by_user.movie_id.values)\n",
    "][\"movie_id\"]\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    ")\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    ")\n",
    "\n",
    "ratings = model.predict(user_movie_array).flatten()\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "print(\"====\" * 9)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"user_rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movie_id.values\n",
    ")\n",
    "movie_df_rows = movie_df[movie_df[\"movie_id\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.movie_id, \":\", ratings_df[ratings_df[\"movie_id\"] == row.movie_id][\"movie_title\"].values[0])  # Asumsikan ada kolom 'genres' di movie_df\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "recommended_movies = movie_df[movie_df[\"movie_id\"].isin(recommended_movie_ids)]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.movie_id, \":\", ratings_df[ratings_df[\"movie_id\"] == row.movie_id][\"movie_title\"].values[0])  # Asumsikan ada kolom 'genres' di movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi gender ke 0 dan 1\n",
    "ratings_df[\"user_gender\"] = ratings_df[\"user_gender\"].astype(int)\n",
    "ratings_df[\"bucketized_user_age\"] = ratings_df[\"bucketized_user_age\"].astype(int)\n",
    "\n",
    "\n",
    "# Normalisasi usia bucket\n",
    "min_age = min(ratings_df[\"bucketized_user_age\"])\n",
    "max_age = max(ratings_df[\"bucketized_user_age\"])\n",
    "\n",
    "# Shuffle data\n",
    "df = ratings_df.sample(frac=1, random_state=42)\n",
    "df[\"age_norm\"] = df[\"bucketized_user_age\"].apply(lambda x: (x - min_age) / (max_age - min_age))\n",
    "x = df[[\"user\", \"movie\", \"user_gender\"]].values\n",
    "# x = df[[\"user\", \"movie\"]].values\n",
    "\n",
    "# Normalisasi rating dan target\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "df[\"rating_norm\"] = df[\"user_rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "df[\"target\"] = df.apply(lambda row: sigmoid(row[\"rating_norm\"] + row[\"like\"]), axis=1)\n",
    "y = df[\"target\"].values\n",
    "\n",
    "# Split data\n",
    "# train_indices = int(0.8 * df.shape[0])\n",
    "# x_train, x_val, y_train, y_val = (\n",
    "#     x[:train_indices],\n",
    "#     x[train_indices:],\n",
    "#     y[:train_indices],\n",
    "#     y[train_indices:],\n",
    "# )\n",
    "\n",
    "train_indices = int(0.8 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iskandar\\Documents\\GitHub\\nbs-ml\\venv-collab\\Lib\\site-packages\\keras\\src\\layers\\layer.py:361: UserWarning: `build()` was called on layer 'recommender_net_35', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"recommender_net_35\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1mModel: \"recommender_net_35\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_184 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_185 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_186 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                        \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m        Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_184 (\u001B[38;5;33mEmbedding\u001B[0m)            │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_185 (\u001B[38;5;33mEmbedding\u001B[0m)            │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_186 (\u001B[38;5;33mEmbedding\u001B[0m)            │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_187 (\u001B[38;5;33mEmbedding\u001B[0m)            │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_188 (\u001B[38;5;33mEmbedding\u001B[0m)            │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_189 (\u001B[38;5;33mEmbedding\u001B[0m)            │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_123 (\u001B[38;5;33mDense\u001B[0m)                    │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_124 (\u001B[38;5;33mDense\u001B[0m)                    │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_125 (\u001B[38;5;33mDense\u001B[0m)                    │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_15 (\u001B[38;5;33mDropout\u001B[0m)                 │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_126 (\u001B[38;5;33mDense\u001B[0m)                    │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "        self.user_gender_embedding = layers.Embedding(\n",
    "            2,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_gender_bias = layers.Embedding(2, 1)\n",
    "        self.dense1 = layers.Dense(32, activation='relu')\n",
    "        self.dense2 = layers.Dense(64, activation='relu')\n",
    "        self.dense3 = layers.Dense(128, activation='relu')\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        user_gender_vector = self.user_gender_embedding(inputs[:, 2])\n",
    "        user_gender_bias = self.user_gender_bias(inputs[:, 2])\n",
    "        # dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # dot_user_movie = tf.tensordot(dot_user_movie, user_gender_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        dot_user_movie = tf.reduce_sum(user_vector * movie_vector, axis=1, keepdims=True)\n",
    "        dot_user_movie_gender = dot_user_movie + tf.reduce_sum(user_vector * user_gender_vector, axis=1, keepdims=True)\n",
    "        dot_user_movie_gender = dot_user_movie_gender + tf.reduce_sum(movie_vector * user_gender_vector, axis=1, keepdims=True)\n",
    "        x = dot_user_movie_gender + user_bias + movie_bias + user_gender_bias\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        # rating_output = tf.nn.sigmoid(x)\n",
    "        # like_output = tf.nn.sigmoid(x)\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return x\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "model.build(input_shape=(None, 3))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step - loss: 0.6200 - root_mean_squared_error: 0.1803 - val_loss: 0.5703 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 2/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5693 - root_mean_squared_error: 0.1015 - val_loss: 0.5701 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 3/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5691 - root_mean_squared_error: 0.1005 - val_loss: 0.5701 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 4/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5688 - root_mean_squared_error: 0.1004 - val_loss: 0.5703 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 5/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5689 - root_mean_squared_error: 0.1004 - val_loss: 0.5703 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 6/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5679 - root_mean_squared_error: 0.0997 - val_loss: 0.5702 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 7/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5685 - root_mean_squared_error: 0.0997 - val_loss: 0.5702 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 8/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5685 - root_mean_squared_error: 0.0999 - val_loss: 0.5703 - val_root_mean_squared_error: 0.1036\n",
      "Epoch 9/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.5684 - root_mean_squared_error: 0.0996 - val_loss: 0.5705 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 10/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5680 - root_mean_squared_error: 0.0993 - val_loss: 0.5705 - val_root_mean_squared_error: 0.1039\n",
      "Epoch 11/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5686 - root_mean_squared_error: 0.0994 - val_loss: 0.5705 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 12/250\n",
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5678 - root_mean_squared_error: 0.0995 - val_loss: 0.5706 - val_root_mean_squared_error: 0.1041\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=1024,\n",
    "    epochs=250,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m52/52\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Showing recommendations for user: 165\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "258 : Contact (1997)\n",
      "326 : G.I. Jane (1997)\n",
      "318 : Schindler's List (1993)\n",
      "169 : Wrong Trousers, The (1993)\n",
      "651 : Glory (1989)\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "285 : Secrets & Lies (1996)\n",
      "302 : L.A. Confidential (1997)\n",
      "641 : Paths of Glory (1957)\n",
      "483 : Casablanca (1942)\n",
      "817 : Frisk (1995)\n",
      "60 : Three Colors: Blue (1993)\n",
      "1113 : Mrs. Parker and the Vicious Circle (1994)\n",
      "513 : Third Man, The (1949)\n",
      "1459 : Madame Butterfly (1995)\n",
      "1443 : 8 Seconds (1994)\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan data frame dengan movieId unik\n",
    "movie_df = ratings_df[['movie_id']].drop_duplicates()\n",
    "\n",
    "# Memilih satu user secara acak\n",
    "user_id = df.user_id.sample(1).iloc[0]\n",
    "movies_watched_by_user = df[df.user_id == user_id]\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df[\"movie_id\"].isin(movies_watched_by_user.movie_id.values)\n",
    "][\"movie_id\"]\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    ")\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "user_gender = df[df[\"user\"] == user_id][\"user_gender\"].iloc[0]\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched, [[user_gender]] * len(movies_not_watched))\n",
    ")\n",
    "\n",
    "ratings = model.predict(user_movie_array).flatten()\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "print(\"====\" * 9)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"user_rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movie_id.values\n",
    ")\n",
    "movie_df_rows = movie_df[movie_df[\"movie_id\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.movie_id, \":\", ratings_df[ratings_df[\"movie_id\"] == row.movie_id][\"movie_title\"].values[0])  # Asumsikan ada kolom 'genres' di movie_df\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "recommended_movies = movie_df[movie_df[\"movie_id\"].isin(recommended_movie_ids)]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.movie_id, \":\", ratings_df[ratings_df[\"movie_id\"] == row.movie_id][\"movie_title\"].values[0])  # Asumsikan ada kolom 'genres' di movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi gender ke 0 dan 1\n",
    "ratings_df[\"user_gender\"] = ratings_df[\"user_gender\"].astype(int)\n",
    "ratings_df[\"bucketized_user_age\"] = ratings_df[\"bucketized_user_age\"].astype(int)\n",
    "\n",
    "\n",
    "# Normalisasi usia bucket\n",
    "min_age = min(ratings_df[\"bucketized_user_age\"])\n",
    "max_age = max(ratings_df[\"bucketized_user_age\"])\n",
    "\n",
    "# Shuffle data\n",
    "df = ratings_df.sample(frac=1, random_state=42)\n",
    "df[\"age_norm\"] = df[\"bucketized_user_age\"].apply(lambda x: (x - min_age) / (max_age - min_age))\n",
    "x = df[[\"user\", \"movie\", \"user_gender\", \"age_norm\"]].values\n",
    "# x = df[[\"user\", \"movie\"]].values\n",
    "\n",
    "num_ages = len(df[\"age_norm\"].unique())\n",
    "num_gender = len(df[\"user_gender\"].unique())\n",
    "\n",
    "# Normalisasi rating dan target\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "df[\"rating_norm\"] = df[\"user_rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "df[\"target\"] = df.apply(lambda row: sigmoid(row[\"rating_norm\"] + row[\"like\"]), axis=1)\n",
    "y = df[\"target\"].values\n",
    "\n",
    "# Split data\n",
    "train_indices = int(0.8 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iskandar\\Documents\\GitHub\\nbs-ml\\venv-collab\\Lib\\site-packages\\keras\\src\\layers\\layer.py:361: UserWarning: `build()` was called on layer 'recommender_net_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"recommender_net_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1mModel: \"recommender_net_10\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                        \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m        Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_80 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_81 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_82 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_83 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_84 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_85 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_86 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_87 (\u001B[38;5;33mEmbedding\u001B[0m)             │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_40 (\u001B[38;5;33mDense\u001B[0m)                     │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_41 (\u001B[38;5;33mDense\u001B[0m)                     │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_42 (\u001B[38;5;33mDense\u001B[0m)                     │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (\u001B[38;5;33mDropout\u001B[0m)                 │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_43 (\u001B[38;5;33mDense\u001B[0m)                     │ ?                           │     \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.utils import register_keras_serializable\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "@register_keras_serializable()\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, num_gender, num_ages, embedding_size, **kwargs):\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.num_gender = num_gender\n",
    "        self.num_ages = num_ages\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "        self.user_gender_embedding = layers.Embedding(\n",
    "            num_gender,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_gender_bias = layers.Embedding(num_gender, 1)\n",
    "        self.age_embedding = layers.Embedding(\n",
    "            num_ages,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.age_bias = layers.Embedding(num_ages, 1)\n",
    "        self.dense1 = layers.Dense(32, activation='relu')\n",
    "        self.dense2 = layers.Dense(64, activation='relu')\n",
    "        self.dense3 = layers.Dense(128, activation='relu')\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        user_gender_vector = self.user_gender_embedding(inputs[:, 2])\n",
    "        user_gender_bias = self.user_gender_bias(inputs[:, 2])\n",
    "        age_vector = self.age_embedding(inputs[:, 3])\n",
    "        age_bias = self.age_bias(inputs[:, 3])\n",
    "        # dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # dot_user_movie = tf.tensordot(dot_user_movie, user_gender_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        dot_user_movie = tf.reduce_sum(user_vector * movie_vector, axis=1, keepdims=True)\n",
    "        dot_user_movie_gender = dot_user_movie + tf.reduce_sum(user_vector * user_gender_vector, axis=1, keepdims=True)\n",
    "        dot_user_movie_gender = dot_user_movie_gender + tf.reduce_sum(movie_vector * user_gender_vector, axis=1, keepdims=True)\n",
    "        dot_user_movie_gender_age = dot_user_movie_gender + tf.reduce_sum(movie_vector * age_vector, axis=1, keepdims=True)\n",
    "        dot_user_movie_gender_age = dot_user_movie_gender_age + tf.reduce_sum(user_vector * age_vector, axis=1, keepdims=True)\n",
    "        dot_user_movie_gender_age = dot_user_movie_gender_age + tf.reduce_sum(user_gender_vector * age_vector, axis=1, keepdims=True)\n",
    "        x = dot_user_movie_gender_age + user_bias + movie_bias + user_gender_bias +age_bias\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        # rating_output = tf.nn.sigmoid(x)\n",
    "        # like_output = tf.nn.sigmoid(x)\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RecommenderNet, self).get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_movies': self.num_movies,\n",
    "            'num_gender': self.num_gender,\n",
    "            'num_ages': self.num_ages,\n",
    "            'embedding_size': self.embedding_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "get_custom_objects().update({'RecommenderNet': RecommenderNet})\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "model = RecommenderNet(num_users, num_movies, num_gender, num_ages, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "model.build(input_shape=(None, 4))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - loss: 0.6117 - root_mean_squared_error: 0.1977 - val_loss: 0.5576 - val_root_mean_squared_error: 0.1297\n",
      "Epoch 2/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5566 - root_mean_squared_error: 0.1259 - val_loss: 0.5527 - val_root_mean_squared_error: 0.1226\n",
      "Epoch 3/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5512 - root_mean_squared_error: 0.1187 - val_loss: 0.5519 - val_root_mean_squared_error: 0.1212\n",
      "Epoch 4/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5501 - root_mean_squared_error: 0.1162 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 5/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5506 - root_mean_squared_error: 0.1158 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 6/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.5504 - root_mean_squared_error: 0.1150 - val_loss: 0.5514 - val_root_mean_squared_error: 0.1204\n",
      "Epoch 7/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.5490 - root_mean_squared_error: 0.1144 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 8/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5481 - root_mean_squared_error: 0.1145 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1206\n",
      "Epoch 9/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5501 - root_mean_squared_error: 0.1148 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 10/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5484 - root_mean_squared_error: 0.1143 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 11/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5499 - root_mean_squared_error: 0.1144 - val_loss: 0.5516 - val_root_mean_squared_error: 0.1207\n",
      "Epoch 12/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5491 - root_mean_squared_error: 0.1143 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 13/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.5489 - root_mean_squared_error: 0.1139 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 14/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.5501 - root_mean_squared_error: 0.1143 - val_loss: 0.5517 - val_root_mean_squared_error: 0.1208\n",
      "Epoch 15/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.5491 - root_mean_squared_error: 0.1140 - val_loss: 0.5515 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 16/250\n",
      "\u001B[1m36/36\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.5490 - root_mean_squared_error: 0.1138 - val_loss: 0.5516 - val_root_mean_squared_error: 0.1206\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=1024,\n",
    "    epochs=250,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Showing recommendations for user: 829\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "595 : To Kill a Mockingbird\n",
      "199 : Star Trek: First Contact\n",
      "1578 : Raging Bull\n",
      "424 : Schindler's List\n",
      "597 : Titanic\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "510 : One Flew Over the Cuckoo's Nest\n",
      "3083 : Mr. Smith Goes to Washington\n",
      "11 : Star Wars\n",
      "489 : Good Will Hunting\n",
      "947 : Lawrence of Arabia\n",
      "85 : Raiders of the Lost Ark\n",
      "4174 : Spellbound\n",
      "289 : Casablanca\n",
      "389 : 12 Angry Men\n",
      "273899 : Stonewall\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan data frame dengan movieId unik\n",
    "movie_df = ratings_df[['movie_id']].drop_duplicates()\n",
    "\n",
    "# Memilih satu user secara acak\n",
    "user_id = df.user_id.sample(1).iloc[0]\n",
    "movies_watched_by_user = df[df.user_id == user_id]\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df[\"movie_id\"].isin(movies_watched_by_user.movie_id.values)\n",
    "][\"movie_id\"]\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    ")\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "user_gender = df[df[\"user_id\"] == user_id][\"user_gender\"].iloc[0]\n",
    "user_age = df[df[\"user_id\"] == user_id][\"age_norm\"].iloc[0]\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched, [[user_gender]] * len(movies_not_watched), [[user_age]] * len(movies_not_watched))\n",
    ")\n",
    "\n",
    "ratings = model.predict(user_movie_array).flatten()\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "print(\"====\" * 9)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"user_rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movie_id.values\n",
    ")\n",
    "movie_df_rows = movie_df[movie_df[\"movie_id\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.movie_id, \":\", ratings_df[ratings_df[\"movie_id\"] == row.movie_id][\"movie_title\"].values[0])  # Asumsikan ada kolom 'genres' di movie_df\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "recommended_movies = movie_df[movie_df[\"movie_id\"].isin(recommended_movie_ids)]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.movie_id, \":\", ratings_df[ratings_df[\"movie_id\"] == row.movie_id][\"movie_title\"].values[0])  # Asumsikan ada kolom 'genres' di movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "folder = './model'\n",
    "if not os.path.exists(folder):\n",
    "  os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open(folder + '/df.pkl', 'wb'))\n",
    "pickle.dump(user2user_encoded, open(folder + '/user_id_encoded.pkl', 'wb'))\n",
    "pickle.dump(movie2movie_encoded, open(folder + '/movie_id_encoded.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucketized_user_age</th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>raw_user_age</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_occupation_label</th>\n",
       "      <th>user_occupation_text</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_zip_code</th>\n",
       "      <th>like</th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>age_norm</th>\n",
       "      <th>rating_norm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "      <td>Money Talks (1997)</td>\n",
       "      <td>19.0</td>\n",
       "      <td>874815542</td>\n",
       "      <td>1</td>\n",
       "      <td>817</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>904</td>\n",
       "      <td>998</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.851953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80184</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>580</td>\n",
       "      <td>Englishman Who Went Up a Hill, But Came Down a...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>883869630</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>485</td>\n",
       "      <td>647</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.851953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>393</td>\n",
       "      <td>Mrs. Doubtfire (1993)</td>\n",
       "      <td>44.0</td>\n",
       "      <td>880088717</td>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>21</td>\n",
       "      <td>writer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134</td>\n",
       "      <td>388</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76699</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>Outbreak (1995)</td>\n",
       "      <td>30.0</td>\n",
       "      <td>888556814</td>\n",
       "      <td>1</td>\n",
       "      <td>774</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>392</td>\n",
       "      <td>580</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.731059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92991</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>420</td>\n",
       "      <td>Alice in Wonderland (1951)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>874957140</td>\n",
       "      <td>0</td>\n",
       "      <td>712</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>341</td>\n",
       "      <td>170</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>Phenomenon (1996)</td>\n",
       "      <td>39.0</td>\n",
       "      <td>885852817</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>engineer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141</td>\n",
       "      <td>39</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>Reservoir Dogs (1992)</td>\n",
       "      <td>51.0</td>\n",
       "      <td>891397819</td>\n",
       "      <td>0</td>\n",
       "      <td>704</td>\n",
       "      <td>10</td>\n",
       "      <td>librarian</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>520</td>\n",
       "      <td>675</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>288</td>\n",
       "      <td>Scream (1996)</td>\n",
       "      <td>26.0</td>\n",
       "      <td>875129640</td>\n",
       "      <td>1</td>\n",
       "      <td>422</td>\n",
       "      <td>5</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>394</td>\n",
       "      <td>162</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>Monty Python and the Holy Grail (1974)</td>\n",
       "      <td>21.0</td>\n",
       "      <td>884207654</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>17</td>\n",
       "      <td>student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176</td>\n",
       "      <td>508</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.679179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>864</td>\n",
       "      <td>My Fellow Americans (1996)</td>\n",
       "      <td>26.0</td>\n",
       "      <td>878962774</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>6</td>\n",
       "      <td>executive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>477</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.562177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bucketized_user_age  movie_genres  movie_id  \\\n",
       "75721                   18             0       876   \n",
       "80184                   35             4       580   \n",
       "19864                   35             4       393   \n",
       "76699                   25             0        54   \n",
       "92991                   18             2       420   \n",
       "...                    ...           ...       ...   \n",
       "6265                    35             7       125   \n",
       "54886                   50             5       156   \n",
       "76820                   25            10       288   \n",
       "860                     18             4       168   \n",
       "15795                   25             4       864   \n",
       "\n",
       "                                             movie_title  raw_user_age  \\\n",
       "75721                                 Money Talks (1997)          19.0   \n",
       "80184  Englishman Who Went Up a Hill, But Came Down a...          40.0   \n",
       "19864                              Mrs. Doubtfire (1993)          44.0   \n",
       "76699                                    Outbreak (1995)          30.0   \n",
       "92991                         Alice in Wonderland (1951)          22.0   \n",
       "...                                                  ...           ...   \n",
       "6265                                   Phenomenon (1996)          39.0   \n",
       "54886                              Reservoir Dogs (1992)          51.0   \n",
       "76820                                      Scream (1996)          26.0   \n",
       "860               Monty Python and the Holy Grail (1974)          21.0   \n",
       "15795                         My Fellow Americans (1996)          26.0   \n",
       "\n",
       "       timestamp  user_gender  user_id  user_occupation_label  \\\n",
       "75721  874815542            1      817                     17   \n",
       "80184  883869630            1       83                     11   \n",
       "19864  880088717            0      389                     21   \n",
       "76699  888556814            1      774                     17   \n",
       "92991  874957140            0      712                     17   \n",
       "...          ...          ...      ...                    ...   \n",
       "6265   885852817            1       25                     18   \n",
       "54886  891397819            0      704                     10   \n",
       "76820  875129640            1      422                      5   \n",
       "860    884207654            0      198                     17   \n",
       "15795  878962774            1      181                      6   \n",
       "\n",
       "      user_occupation_text  user_rating user_zip_code  like  user  movie  \\\n",
       "75721              student          4.0         60152   1.0   904    998   \n",
       "80184                other          4.0         44133   1.0   485    647   \n",
       "19864               writer          2.0         83702   1.0   134    388   \n",
       "76699              student          1.0         80027   1.0   392    580   \n",
       "92991              student          3.0         54901   1.0   341    170   \n",
       "...                    ...          ...           ...   ...   ...    ...   \n",
       "6265              engineer          5.0         55107   1.0   141     39   \n",
       "54886            librarian          3.0         91105   1.0   520    675   \n",
       "76820        entertainment          3.0         94533   1.0   394    162   \n",
       "860                student          4.0         55414   0.0   176    508   \n",
       "15795            executive          2.0         21218   0.0   171    477   \n",
       "\n",
       "       age_norm  rating_norm    target  \n",
       "75721  0.309091         0.75  0.851953  \n",
       "80184  0.618182         0.75  0.851953  \n",
       "19864  0.618182         0.25  0.777300  \n",
       "76699  0.436364         0.00  0.731059  \n",
       "92991  0.309091         0.50  0.817574  \n",
       "...         ...          ...       ...  \n",
       "6265   0.618182         1.00  0.880797  \n",
       "54886  0.890909         0.50  0.817574  \n",
       "76820  0.436364         0.50  0.817574  \n",
       "860    0.309091         0.75  0.679179  \n",
       "15795  0.436364         0.25  0.562177  \n",
       "\n",
       "[100000 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load(open(folder + '/df.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder + '/model_collab.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
